# avito_paid_cvs_save_v_16.py
# -*- coding: utf-8 -*-
from __future__ import annotations

"""
Avito: –ö—É–ø–ª–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ ‚Üí XLSX —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç–∞—Ç—É—Å–æ–≤ —á–∞—Ç–æ–≤ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π.

v16 = v15 + –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –õ–û–ì–ò–ö–ò –ü–ê–†–°–ò–ù–ì–ê –ß–ê–¢–û–í  
  ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤—Å–µ—Ö —á–∞—Ç–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä—å
  ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏ offset –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API
  ‚Ä¢ –ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —á–∞—Ç–æ–≤
  ‚Ä¢ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ—Ç–µ—Ä–µ–π ~900 —á–∞—Ç–æ–≤ –∏–∑ ~2000

v15 = v14 + –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø
  ‚Ä¢ (–∫–æ–ø–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –∏–∑ v14)

v14 = v13 + –ö–û–ù–¢–†–û–õ–¨–ù–ê–Ø –¶–ò–§–†–ê –ò–ó –ò–ó–ë–†–ê–ù–ù–û–ì–û + –ê–ì–†–ï–°–°–ò–í–ù–´–ô –ü–ê–†–°–ò–ù–ì
  ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã –∏–∑ https://www.avito.ru/favorites?categoryId=112
  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã –∫–∞–∫ —Ç–æ—á–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
  ‚Ä¢ –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
  ‚Ä¢ –£–±—Ä–∞–Ω—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ç–æ–ø—ã, –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –¥–æ —Ü–µ–ª–∏
  ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º —Ä–µ–∑—é–º–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ

–ö–≠–®–ò–†–û–í–ê–ù–ù–´–ï –ß–ê–¢–´:
  ‚Ä¢ –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —á–∞—Ç–æ–≤ –∏–∑ avito_chats_cache_builder
  ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∫—ç—à–∞ avito_chats_cache.json
  ‚Ä¢ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã
"""

# –û—Ç–∫–ª—é—á–∞–µ–º —Ü–∏—Ä–∫—É–ª—è—Ä–Ω—ã–π –∏–º–ø–æ—Ä—Ç –∏–∑ –∫—ç—à-–±–∏–ª–¥–µ—Ä–∞
# from avito_chats_cache_builder import fetch_individual_chat, load_chats_cache, save_chats_cache

"""
–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤–µ—Ä—Å–∏–π:

v15 = v14 + –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø
  ‚Ä¢ –û—á–∏—Å—Ç–∫–∞ –∫—É–∫–æ–≤ (–∫—Ä–æ–º–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö) –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–µ—Å—Å–∏–∏
  ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–∫–Ω–æ –±—Ä–∞—É–∑–µ—Ä–∞ 1200x800 –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏

v13 = v12 + –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ë–†–ê–£–ó–ï–†–ù–û–ô –ó–ê–ì–†–£–ó–ö–ò
  ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –±—Ä–∞—É–∑–µ—Ä–Ω–æ–π —á–∞—Å—Ç–∏
  ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∏ –æ–∂–∏–¥–∞–Ω–∏—è
  ‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–æ–ª–ª–∏–Ω–≥ —Å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
  ‚Ä¢ –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –¥–æ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Ä–µ–∑—é–º–µ
  ‚Ä¢ –°—Ç–∞—Ç—É—Å-–∏–Ω–¥–∏–∫–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
  ‚Ä¢ –†–∞–Ω–¥–æ–º–Ω–æ–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞–≤–∏—Å–∞–Ω–∏–∏ —Å 20-—Å–µ–∫—É–Ω–¥–Ω—ã–º –æ–∂–∏–¥–∞–Ω–∏–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
  ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π

v12 = v11 + –õ–ò–°–¢ "–ö–û–ú–£ –ù–ï –ü–ò–°–ê–õ–ò"
  ‚Ä¢ –ù–æ–≤—ã–π –ª–∏—Å—Ç "–ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏" —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏ —É –∫–æ—Ç–æ—Ä—ã—Ö chat_status = "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"
  ‚Ä¢ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –≤ –ª–∏—Å—Ç–µ "–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤" –ø–ª—é—Å —Å—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç
  ‚Ä¢ –í–∫–ª—é—á–∞–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ —Å—Ç–æ–ø-–ª–∏—Å—Ç–∞ —Ç–æ–∂–µ
  ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø–æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–±–æ—Ç–µ

CLI:
  python avito_paid_cvs_save_v_16.py --tz Europe/Moscow --threads 8

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
  pip install playwright pandas openpyxl requests tzdata
  python -m playwright install chromium
"""

from pathlib import Path
from datetime import datetime, timedelta, timezone
from playwright.sync_api import sync_playwright, Error as PwError
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum
from typing import List, Dict, Optional, Tuple
import re, time, json, sys, os
import pandas as pd

# ========== –¢–ò–ü–ò–ó–ê–¶–ò–Ø –°–¢–ê–¢–£–°–û–í –ß–ê–¢–û–í ==========

class ChatStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã —á–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    READ_NO_REPLY = "–ü—Ä–æ—á–∏—Ç–∞–ª/–Ω–µ –æ—Ç–≤–µ—Ç–∏–ª"           # –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª, –Ω–æ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª
    READ_REPLIED = "–ü—Ä–æ—á–∏—Ç–∞–ª/–û—Ç–≤–µ—Ç–∏–ª"               # –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª –∏ –æ—Ç–≤–µ—Ç–∏–ª
    NO_MESSAGES_SENT = "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"      # –ú—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    NOT_INTERESTED = "–ù–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ"                 # –ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–ø–∏—Å–∞–ª, —á—Ç–æ –Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ
    NO_CHAT = "–ß–∞—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"                     # –ù–µ—Ç —á–∞—Ç–∞ —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º
    UNKNOWN = "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π"                      # –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å

class MessageDirection(Enum):
    """–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    IN = "in"               # –í—Ö–æ–¥—è—â–µ–µ (–æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞)
    OUT = "out"             # –ò—Å—Ö–æ–¥—è—â–µ–µ (–æ—Ç –Ω–∞—Å)

# ===== TZ helper =====
try:
    from zoneinfo import ZoneInfo  # Python 3.9+
except Exception:
    try:
        from backports.zoneinfo import ZoneInfo  # type: ignore
    except Exception:
        ZoneInfo = None  # type: ignore

DEFAULT_TZ_NAME = "Europe/Moscow"

# ===== –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï =====
CHATS_DATA: Dict[str, Dict] = {}  # –î–∞–Ω–Ω—ã–µ —á–∞—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞
NOT_FOUND_CHATS: List[str] = []  # –ß–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ loaded data (–∫–æ–º—É –Ω–µ –ø–∏—Å–∞–ª–∏)

def _get_tz(tz_name: str):
    tz_name = (tz_name or DEFAULT_TZ_NAME).strip()
    if ZoneInfo is not None:
        try:
            return ZoneInfo(tz_name)
        except Exception:
            pass
    if tz_name in ("Europe/Moscow", "MSK", "RU-MOW"):
        return timezone(timedelta(hours=3))
    return timezone.utc

# ===== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ–±-—á–∞—Å—Ç–∏ =====
HOME_URL   = "https://www.avito.ru/"
TARGET_URL = "https://www.avito.ru/profile/paid-cvs"

# v15: –°—Ç–æ–ø-—Ç—Ä–∏–≥–≥–µ—Ä –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç #1)
STOP_TRIGGER_URL = "https://www.avito.ru/kotelniki/rezume/kassir_prodavets_sidelka_ofitsiantka_4162899311"

USER_DATA_DIR = Path("./avito_browser_profile").resolve()
OUTPUT_DIR    = Path("./saved_pages").resolve(); OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

NAV_TIMEOUT            = 60_000
MAX_TOTAL_SCROLL_SEC   = 420
QUIET_MS               = 2000
STABLE_GROWTH_ROUNDS   = 5
MAX_WHEEL_STEPS        = 480
WHEEL_DELAY_SEC        = 0.20
WAIT_RESP_TIMEOUT_MS   = 6000
NETWORK_IDLE_GRACE     = 2

# ========== –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è/HTTP –∫ Avito API ==========
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

API_BASE = "https://api.avito.ru"
TIMEOUT  = 30

APP_NAME = "Resume Sercher"
CLIENT_ID     = "Dm4ruLMEr9MFsV72dN95"
CLIENT_SECRET = "f73lNoAJLzuqwoGtVaMnByhQfSlwcyIN_m7wyOeT"
REDIRECT_URL  = "https://hireworkers.ru/"

SESSION = requests.Session()
retry_cfg = Retry(
    total=5, connect=5, read=5,
    backoff_factor=0.5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=frozenset(["GET", "POST"]),
    raise_on_status=False,
)
SESSION.mount("https://", HTTPAdapter(max_retries=retry_cfg, pool_connections=10, pool_maxsize=10))
SESSION.headers.update({"User-Agent": f"{APP_NAME} / avito_paid_cvs_save_v6_6", "Accept": "application/json"})

class Token:
    def __init__(self) -> None:
        self._token: str | None = None
        self._exp: float = 0.0
        self.force_refresh_on_start = True
    def _refresh(self) -> None:
        r = SESSION.post(
            f"{API_BASE}/token",
            data={"grant_type": "client_credentials", "client_id": CLIENT_ID, "client_secret": CLIENT_SECRET},
            timeout=TIMEOUT,
        )
        r.raise_for_status()
        js = r.json()
        self._token = js["access_token"]
        self._exp = time.time() + int(js.get("expires_in", 3600)) - 20
        print("üîë access_token –æ–±–Ω–æ–≤–ª—ë–Ω")
    def get(self) -> str:
        if self.force_refresh_on_start or self._token is None or time.time() >= self._exp:
            self._refresh()
            self.force_refresh_on_start = False
        return self._token  # type: ignore[return-value]
_tok = Token()

import threading

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è rate limiting
_rate_limit_lock = threading.Lock()
_last_request_time = 0.0

def fetch_individual_chat(chat_id: str, headers: dict, user_id: int) -> Optional[Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —á–∞—Ç –ø–æ –µ–≥–æ ID —á–µ—Ä–µ–∑ API v2
    """
    try:
        chat_url = f"{API_BASE}/messenger/v2/accounts/{user_id}/chats/{chat_id}"
        response = SESSION.get(chat_url, headers=headers, timeout=TIMEOUT)
        
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 404:
            # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º 404 –∫–∞–∫ –æ—à–∏–±–∫—É - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —á–∞—Ç–æ–≤
            return None
        else:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–∞ {chat_id}: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–∞—Ç–∞ {chat_id}: {e}")
        return None

def load_chats_cache(cache_file: str = "avito_chats_cache.json") -> Optional[Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à —á–∞—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞
    """
    cache_path = Path(cache_file)
    if not cache_path.exists():
        return None
        
    try:
        with open(cache_path, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
        return cache_data
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
        return None

def save_chats_cache(chats_dict: Dict[str, Dict], cache_file: str = "avito_chats_cache.json") -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à —á–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª
    """
    try:
        cache_data = {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "total_chats": len(chats_dict),
                "script_version": "v16"
            },
            "chats": chats_dict
        }
        
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")
        return False

def _respect_rate_limit(resp: requests.Response) -> None:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π rate limiting —Å –∞–Ω–∞–ª–∏–∑–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤."""
    global _last_request_time
    
    try:
        with _rate_limit_lock:
            remain = int(resp.headers.get("X-RateLimit-Remaining", "5"))
            limit = int(resp.headers.get("X-RateLimit-Limit", "100"))
            reset_time = resp.headers.get("X-RateLimit-Reset")
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤
            if remain <= 1:
                sleep_time = 1.0
            elif remain <= 5:
                sleep_time = 0.3
            elif remain <= 10:
                sleep_time = 0.1
            else:
                sleep_time = 0.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            
            # –£—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            current_time = time.time()
            elapsed = current_time - _last_request_time
            if elapsed < sleep_time:
                time.sleep(sleep_time - elapsed)
            
            _last_request_time = time.time()
            
    except Exception:
        # Fallback: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        time.sleep(0.05)

def avito_get_json(path: str, *, params: dict | None = None, timeout: int | None = None) -> dict:
    to = timeout or TIMEOUT
    for attempt in (1, 2):
        try:
            resp = SESSION.get(API_BASE + path, headers={"Authorization": "Bearer " + _tok.get()}, params=params, timeout=to)
            if resp.status_code == 200:
                _respect_rate_limit(resp)
                return resp.json()
            if resp.status_code in (401, 403) and attempt == 1:
                print(f"‚ö†Ô∏è  {resp.status_code} –Ω–∞ {path}. –û–±–Ω–æ–≤–ª—è—é —Ç–æ–∫–µ–Ω‚Ä¶")
                _tok.force_refresh_on_start = True
                _tok.get()
                continue
            print(f"‚ö†Ô∏è  GET {path} ‚Üí HTTP {resp.status_code}: {resp.text[:200]}...")
            return {}
        except requests.RequestException as e:
            if attempt == 1:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –Ω–∞ {path}: {e}. –†–µ—Ñ—Ä–µ—à —Ç–æ–∫–µ–Ω–∞‚Ä¶")
                _tok.force_refresh_on_start = True
                _tok.get()
                continue
            print(f"‚õî  –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –Ω–∞ {path} (–ø–æ–≤—Ç–æ—Ä –Ω–µ –ø–æ–º–æ–≥): {e}")
            return {}
    return {}

def _ensure_my_user_id() -> int:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞—à user_id –∏–∑ /core/v1/accounts/self.
    –¢–æ–∫–µ–Ω –±–µ—Ä—ë–º —á–µ—Ä–µ–∑ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π _tok/SESSION.
    """
    try:
        resp = SESSION.get(
            API_BASE + "/core/v1/accounts/self",
            headers={"Authorization": "Bearer " + _tok.get()},
            timeout=TIMEOUT,
        )
        if resp.status_code != 200:
            raise RuntimeError(f"/accounts/self HTTP {resp.status_code}: {resp.text[:200]}")
        data = resp.json() or {}
        uid = data.get("id") or data.get("user_id")
        if not uid:
            raise RuntimeError(f"/accounts/self: –ø–æ–ª–µ id/user_id –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {data}")
        return int(uid)
    except Exception as e:
        print(f"‚õî  _ensure_my_user_id() error: {e}")
        return 0

# ========== –ê–ù–ê–õ–ò–ó –°–¢–ê–¢–£–°–û–í –ß–ê–¢–û–í –ò –°–û–û–ë–©–ï–ù–ò–ô ==========

def load_chats_from_cache_and_api() -> Dict[str, Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–∞—Ç—ã –∏–∑ –∫—ç—à–∞ –∏ –¥–æ–ø–æ–ª–Ω—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —á–µ—Ä–µ–∑ API
    """
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —á–∞—Ç–æ–≤ –∏–∑ –∫—ç—à–∞...")
    
    cache_file = "avito_chats_cache.json"
    cache_path = Path(cache_file)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫—ç—à–∞
    chats_dict = {}
    if cache_path.exists():
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            chats_dict = cache_data.get("chats", {})
            metadata = cache_data.get("metadata", {})
            
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫—ç—à–∞: {len(chats_dict)} —á–∞—Ç–æ–≤")
            print(f"üìÖ –ö—ç—à —Å–æ–∑–¥–∞–Ω: {metadata.get('created_at', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
            chats_dict = {}
    else:
        print(f"‚ö†Ô∏è –ö—ç—à —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {cache_path}")
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ avito_chats_cache_builder.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞")
    
    return chats_dict

def add_missing_chats_to_cache(missing_chat_ids: List[str], cache_file="avito_chats_cache.json") -> int:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —á–∞—Ç—ã —á–µ—Ä–µ–∑ API –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –∫—ç—à
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤
    """
    if not missing_chat_ids:
        return 0
    
    print(f"üîç –ó–∞–≥—Ä—É–∂–∞–µ–º {len(missing_chat_ids)} –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API...")
    
    try:
        token = _tok.get()
        user_id = _ensure_my_user_id()
        
        if not token or not user_id:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω/user_id")
            return 0
        
        headers = {'Authorization': f'Bearer {token}'}
        new_chats = {}
        recovered_count = 0
        
        for i, chat_id in enumerate(missing_chat_ids):
            try:
                individual_chat = fetch_individual_chat(chat_id, headers, user_id)
                if individual_chat:
                    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫—ç—à–∞
                    individual_chat['_cached_at'] = datetime.now().isoformat()
                    individual_chat['_cache_version'] = 1
                    new_chats[chat_id] = individual_chat
                    recovered_count += 1
                    
                    if recovered_count % 50 == 0:
                        print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {recovered_count}/{len(missing_chat_ids)} —á–∞—Ç–æ–≤...")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if i % 100 == 0 and i > 0:
                    print(f"‚è∏Ô∏è –ü–∞—É–∑–∞ –ø–æ—Å–ª–µ {i} –∑–∞–ø—Ä–æ—Å–æ–≤...")
                    time.sleep(2)
                else:
                    time.sleep(0.05)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–∞ {chat_id}: {e}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ —á–∞—Ç—ã
        if new_chats:
            print(f"üíæ –î–æ–±–∞–≤–ª—è–µ–º {len(new_chats)} –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤ –≤ –∫—ç—à...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à
            cache_path = Path(cache_file)
            existing_cache = {}
            
            if cache_path.exists():
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                    existing_cache = cache_data.get("chats", {})
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫—ç—à–∞: {e}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —á–∞—Ç—ã
            existing_cache.update(new_chats)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫—ç—à
            cache_data = {
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "total_chats": len(existing_cache),
                    "version": 1,
                    "last_updated": datetime.now().isoformat()
                },
                "chats": existing_cache
            }
            
            try:
                with open(cache_path, 'w', encoding='utf-8') as f:
                    json.dump(cache_data, f, ensure_ascii=False, indent=2)
                print(f"‚úÖ –ö—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω: —Ç–µ–ø–µ—Ä—å {len(existing_cache)} —á–∞—Ç–æ–≤")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")
        
        return recovered_count
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫—ç—à–∞: {e}")
        return 0

def load_chats_from_api() -> Dict[str, Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–∞—Ç—ã –∏–∑ –∫—ç—à–∞ (–±–µ–∑ API –∑–∞–ø—Ä–æ—Å–æ–≤)
    """
    return load_chats_from_cache_and_api()


def load_chats_from_json(json_file_path: str = "avito_export_20250920_015400.json") -> Dict[str, Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {chat_id: chat_data} –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞.
    """
    if not os.path.exists(json_file_path):
        print(f"‚ö†Ô∏è  Chat JSON file not found: {json_file_path}")
        return {}
        
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        chats = data.get("chats", [])
        chat_dict = {}
        
        for chat in chats:
            chat_id = chat.get("id")
            if chat_id:
                chat_dict[chat_id] = chat
                
        print(f"‚úÖ Loaded {len(chat_dict)} chats from {json_file_path}")
        return chat_dict
        
    except Exception as e:
        print(f"‚õî Error loading chats from JSON: {e}")
        return {}


def analyze_chat_from_json(chat_data: Dict) -> Tuple[str, str, str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–∞ –∏–∑ JSON —ç–∫—Å–ø–æ—Ä—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (chat_status, last_message_direction, last_message_text)
    """
    if not chat_data:
        return ChatStatus.NO_CHAT.value, "", ""
        
    last_message = chat_data.get("last_message", {})
    if not last_message:
        return ChatStatus.NO_MESSAGES_SENT.value, "", ""
        
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    direction = last_message.get("direction", "").lower()
    message_text = ""
    content = last_message.get("content", {})
    if isinstance(content, dict):
        message_text = content.get("text", "")[:500]  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É
        
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    if direction == "in":
        last_message_direction = "–í—Ö–æ–¥—è—â–µ–µ"
    elif direction == "out":
        last_message_direction = "–ò—Å—Ö–æ–¥—è—â–µ–µ"
    else:
        last_message_direction = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—á—Ç–µ–Ω–∏—è
    read_timestamp = last_message.get("read")
    delivered_timestamp = last_message.get("delivered")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —á–∞—Ç–∞
    if direction == "in":
        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Ö–æ–¥—è—â–µ–µ - –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–ø–∏—Å–∞–ª
        if read_timestamp:
            chat_status = ChatStatus.READ_NO_REPLY.value  # –ü—Ä–æ—á–∏—Ç–∞–ª–∏, –Ω–æ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∏
        else:
            chat_status = ChatStatus.READ_NO_REPLY.value  # –í—Ö–æ–¥—è—â–∏–µ –æ–±—ã—á–Ω–æ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–º–∏
    elif direction == "out":
        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏—Å—Ö–æ–¥—è—â–µ–µ - –º—ã –Ω–∞–ø–∏—Å–∞–ª–∏
        if read_timestamp:
            chat_status = ChatStatus.READ_REPLIED.value  # –û—Ç–ø—Ä–∞–≤–∏–ª–∏ –∏ –∫–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª
        else:
            chat_status = ChatStatus.NO_MESSAGES_SENT.value  # –û—Ç–ø—Ä–∞–≤–∏–ª–∏, –Ω–æ –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ
    else:
        chat_status = ChatStatus.UNKNOWN.value
        
    return chat_status, last_message_direction, message_text


def get_chat_messages(chat_id: str, limit: int = 100) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞ –ø–æ chat_id.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π.
    """
    if not chat_id:
        return []

    my_uid = _ensure_my_user_id()
    if not my_uid:
        return []

    try:
        url = f"{API_BASE}/messenger/v3/accounts/{my_uid}/chats/{chat_id}/messages/"
        params = {"limit": min(limit, 100), "offset": 0}
        r = SESSION.get(url, headers={"Authorization": "Bearer " + _tok.get()}, params=params, timeout=TIMEOUT)
        
        if r.status_code != 200:
            return []
            
        payload = r.json() or {}
        
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        messages = []
        if isinstance(payload.get("messages"), list):
            messages = payload["messages"]
        elif isinstance(payload.get("messages"), dict) and isinstance(payload["messages"].get("messages"), list):
            messages = payload["messages"]["messages"]
        elif isinstance(payload.get("result"), list):
            messages = payload["result"]
            
        return messages
        
    except Exception as e:
        print(f"‚ö†Ô∏è get_chat_messages error for {chat_id}: {e}")
        return []


def determine_chat_status(chat_id: str, my_user_id: int) -> tuple[ChatStatus, Optional[str], Optional[str]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å —á–∞—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        (chat_status, last_message_direction, last_message_text)
    """
    if not chat_id:
        return ChatStatus.NO_CHAT, None, None
    
    messages = get_chat_messages(chat_id, limit=50)
    if not messages:
        return ChatStatus.NO_CHAT, None, None
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞)
    messages.sort(key=lambda m: m.get('created', 0), reverse=True)
    
    our_messages = []
    candidate_messages = []
    
    for msg in messages:
        direction = str(msg.get('direction', '')).lower()
        author_id = msg.get('author_id')
        
        try:
            author_id = int(author_id) if author_id else None
        except:
            author_id = None
        
        if direction == MessageDirection.OUT.value:
            our_messages.append(msg)
        elif direction == MessageDirection.IN.value:
            candidate_messages.append(msg)
        elif author_id == my_user_id:
            our_messages.append(msg)
        elif author_id and author_id != my_user_id:
            candidate_messages.append(msg)
    
    # –ï—Å–ª–∏ –º—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    if not our_messages:
        return ChatStatus.NO_MESSAGES_SENT, None, None
    
    # –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–ª
    if not candidate_messages:
        return ChatStatus.READ_NO_REPLY, MessageDirection.OUT.value, None
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    last_message = messages[0] if messages else None
    last_message_direction = None
    last_message_text = None
    
    if last_message:
        last_direction = str(last_message.get('direction', '')).lower()
        last_author_id = last_message.get('author_id')
        
        try:
            last_author_id = int(last_author_id) if last_author_id else None
        except:
            last_author_id = None
        
        if last_direction == MessageDirection.IN.value or (last_author_id and last_author_id != my_user_id):
            last_message_direction = MessageDirection.IN.value
        else:
            last_message_direction = MessageDirection.OUT.value
        
        last_message_text = last_message.get('content', {}).get('text', '') if last_message.get('content') else ''
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–∞—Ç—É—Å
    if candidate_messages:
        chat_status = ChatStatus.READ_REPLIED
    else:
        chat_status = ChatStatus.READ_NO_REPLY
    
    return chat_status, last_message_direction, last_message_text


# ‚Äî‚Äî‚Äî Avito Job API wrappers

def get_resume_open_json(resume_id: str) -> dict:
    """GET /job/v2/resumes/{id} ‚Äî –æ—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ (Resume 2.0)."""
    return avito_get_json(f"/job/v2/resumes/{resume_id}") or {}

def get_resume_paid_contacts_json(resume_id: str) -> dict:
    """GET /job/v1/resumes/{id}/contacts ‚Äî –∫—É–ø–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã (ResumeContacts)."""
    js = avito_get_json(f"/job/v1/resumes/{resume_id}/contacts", timeout=TIMEOUT + 10)
    if js:
        return js
    return avito_get_json(f"/job/v1/resumes/{resume_id}/contacts/", timeout=TIMEOUT + 10) or {}

# ========== –°–∫—Ä–æ–ª–ª/—ç–∫—Å—Ç—Ä–∞–∫—Ç ==========
ROBUST_SCROLL_LIMIT_JS = rf"""
  async (need) => {{
    const deadline = Date.now() + {MAX_TOTAL_SCROLL_SEC} * 1000;
    const quietMs  = {QUIET_MS};
    document.documentElement.style.scrollBehavior = 'auto';
    const sleep = (ms) => new Promise(r => setTimeout(r, ms));
    const norm = s => (s||'').replace(/\s+/g,' ').trim();
    const listSelector = '[data-marker="cv-snippet"]';

    let lastMutation = Date.now();
    const mo = new MutationObserver(() => {{ lastMutation = Date.now(); }});
    mo.observe(document.body, {{childList:true, subtree:true}});

    // –°—Ç–∞—Ç—É—Å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    let totalScrollTime = 0;
    let lastStatusUpdate = Date.now();
    
    const logStatus = (message) => {{
      const elapsed = Math.round((Date.now() - (deadline - {MAX_TOTAL_SCROLL_SEC} * 1000)) / 1000);
      console.log(`[SCROLL ${{elapsed}}s] ${{message}}`);
    }};

    async function clickMore() {{
      const reMore = /(–ø–æ–∫–∞–∑–∞—Ç[—å—ä]\s*–µ—â[–µ—ë]|–ø–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ|–µ—â—ë|–∑–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë)/i;
      const btns = Array.from(document.querySelectorAll('button,a')).filter(b => reMore.test(norm(b.textContent)));
      for (const b of btns) {{ if (!b.disabled && !b.getAttribute('aria-disabled')) {{ b.click(); await sleep(400); }} }}
    }}

    // –§—É–Ω–∫—Ü–∏—è —Ä–∞–Ω–¥–æ–º–Ω–æ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –ø—Ä–∏ –∑–∞–≤–∏—Å–∞–Ω–∏–∏
    async function performStuckRecovery() {{
      logStatus("‚ö†Ô∏è –ó–∞–≤–∏—Å–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ - –≤—ã–ø–æ–ª–Ω—è—é —Å–ª—É—á–∞–π–Ω—ã–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è");
      
      // 1. –ù–µ–º–Ω–æ–≥–æ —Ä–∞–Ω–¥–æ–º–Ω–æ –ø—Ä–æ–ª–∏—Å—Ç–Ω–∏ –≤–≤–µ—Ä—Ö—É
      for (let i = 0; i < 3; i++) {{
        const randomY = Math.random() * 500 + 200;
        window.scrollTo(0, randomY);
        await sleep(1000 + Math.random() * 1000);
      }}
      
      // 2. –ù–∞ —Å–∞–º—ã–π –≤–µ—Ä—Ö
      window.scrollTo(0, 0);
      await sleep(2000);
      logStatus("üìç –ü–µ—Ä–µ–º–µ—Å—Ç–∏–ª—Å—è –Ω–∞ –≤–µ—Ä—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã");
      
      // 3. –í —Å–∞–º—ã–π –Ω–∏–∑
      window.scrollTo(0, document.body.scrollHeight);
      await sleep(2000);
      logStatus("üìç –ü–µ—Ä–µ–º–µ—Å—Ç–∏–ª—Å—è –≤ –Ω–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã");
      
      // 4. –ñ–¥–µ–º 20 —Å–µ–∫—É–Ω–¥ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å
      logStatus("‚è±Ô∏è –û–∂–∏–¥–∞–Ω–∏–µ 20 —Å–µ–∫—É–Ω–¥...");
      const beforeWaitCount = cards().length;
      await sleep(20000);
      const afterWaitCount = cards().length;
      
      if (afterWaitCount > beforeWaitCount) {{
        logStatus(`‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ë—ã–ª–æ: ${{beforeWaitCount}}, —Å—Ç–∞–ª–æ: ${{afterWaitCount}}`);
        return true; // –ü—Ä–æ—Ü–µ—Å—Å –ø–æ—à–µ–ª
      }} else {{
        logStatus(`‚ùå –ü—Ä–æ—Ü–µ—Å—Å –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è. –û—Å—Ç–∞–µ—Ç—Å—è: ${{afterWaitCount}}`);
        return false; // –ü—Ä–æ—Ü–µ—Å—Å –Ω–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è
      }}
    }}

    let lastCount = 0, stableRounds = 0;
    const cards = () => Array.from(document.querySelectorAll(listSelector));
    
    logStatus(`üöÄ –ù–∞—á–∞–ª–æ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥–∞, –ª–∏–º–∏—Ç: ${{need || '–ù–ï–¢'}}`);

    while (Date.now() < deadline) {{
      window.scrollTo(0, document.body.scrollHeight);
      await sleep(600); // –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
      await clickMore();

      window.scrollBy(0, -200); 
      await sleep(200); // –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
      window.scrollTo(0, document.body.scrollHeight); 
      await sleep(600); // –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ

      const curCount = cards().length;
      const quiet = (Date.now() - lastMutation) > quietMs;
      
      // –°—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 15 —Å–µ–∫—É–Ω–¥
      if (Date.now() - lastStatusUpdate > 15000) {{
        logStatus(`üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–µ–∑—é–º–µ: ${{curCount}}, —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–∞—É–Ω–¥–æ–≤: ${{stableRounds}}`);
        lastStatusUpdate = Date.now();
      }}
      
      if (curCount <= lastCount && quiet) {{
        stableRounds++;
        
        // –ï—Å–ª–∏ –∑–∞–≤–∏—Å–∞–Ω–∏–µ –¥–ª–∏—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
        if (stableRounds >= 8) {{ // –†–∞–Ω—å—à–µ –±—ã–ª–æ {STABLE_GROWTH_ROUNDS}
          const recovered = await performStuckRecovery();
          if (recovered) {{
            stableRounds = 0; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            lastCount = cards().length;
            lastMutation = Date.now(); // –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –º—É—Ç–∞—Ü–∏–∏
            continue; // –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Å—Ö–µ–º–µ
          }}
        }}
      }} else {{ 
        stableRounds = 0; 
        lastCount = curCount; 
      }}
      
      if (need && curCount >= need) {{
        logStatus(`‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç: ${{curCount}}/${{need}}`);
        break;
      }}
      if (stableRounds >= {STABLE_GROWTH_ROUNDS}) {{
        logStatus(`‚èπÔ∏è –°–∫—Ä–æ–ª–ª–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –ø–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: ${{stableRounds}} —Ä–∞—É–Ω–¥–æ–≤`);
        break;
      }}
    }}

    logStatus("üîÑ –ü–µ—Ä–µ—Ö–æ–¥ –∫ –¥–µ—Ç–∞–ª—å–Ω–æ–º—É —Å–∫—Ä–æ–ª–ª–∏–Ω–≥—É");
    let before = cards().length;
    for (let i = 0; i < cards().length && Date.now() < deadline; i++) {{
      try {{ cards()[i].scrollIntoView({{block:'center'}}); }} catch(e) {{}}
      await sleep(160); // –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–æ
      await clickMore();
      window.scrollBy(0, 120); await sleep(100); window.scrollBy(0, -120);
      await sleep(140); // –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–æ
      const cur = cards().length;
      if (need && cur >= need) break;
      if (cur > before) {{ before = cur; i = Math.max(0, i-3); }}
    }}

    logStatus("üîÑ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞");
    for (let k=0;k<10;k++) {{
      window.scrollTo(0, document.body.scrollHeight); 
      await sleep(500); // –£–≤–µ–ª–∏—á–µ–Ω–æ
      await clickMore();
      if (need && cards().length >= need) break;
    }}

    mo.disconnect();
    const total = cards().length;
    logStatus(`üèÅ –°–∫—Ä–æ–ª–ª–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ —Ä–µ–∑—é–º–µ: ${{total}}`);
    return need ? Math.min(total, need) : total;
  }}
"""

COUNT_CARDS_JS = '() => document.querySelectorAll(\'[data-marker="cv-snippet"]\').length'

EXTRACT_JS = r"""
  () => {
    const norm = s => (s||'').replace(/\s+/g,' ').trim();
    const q = (root, sel) => root.querySelector(sel);

    const getDateText = (card, preferSel, labelRx) => {
      for (const sel of preferSel) {
        const el = sel ? card.querySelector(sel) : null;
        const txt = norm(el?.textContent);
        if (txt) return txt;
      }
      const full = norm(card.textContent || '');
      const m = full.match(labelRx);
      return m ? norm(m[0]) : '';
    };

    const out = [], seen = new Set();
    const cards = Array.from(document.querySelectorAll('[data-marker="cv-snippet"]'));

    for (const card of cards) {
      const linkEl = card.querySelector('a[href]');
      const link = linkEl ? new URL(linkEl.getAttribute('href'), location.origin).href : '';
      const rid  = (link.match(/\/(\d+)(?:\?|$)/)||[])[1] || '';

      const purchasedRaw = getDateText(
        card,
        ['[data-marker="cv-snippet/date/item-bought"]', '[data-marker*="date"]'],
        /(–ö—É–ø–ª–µ–Ω–æ\s+(?:—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|\d{1,2}\s+[–ê-–Ø–∞-—è–Å—ë\.]+(?:\s+\d{4})?\s+–≤\s+\d{1,2}:\d{2}))/i
      );
      const updatedRaw = getDateText(
        card,
        ['[data-marker="cv-snippet/date/item-changed"]', '[data-marker*="date"]'],
        /((?:–û–±–Ω–æ–≤–ª–µ–Ω–æ|–£–¥–∞–ª–µ–Ω–æ)\s+(?:—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|\d{1,2}\s+[–ê-–Ø–∞-—è–Å—ë\.]+(?:\s+\d{4})?\s+–≤\s+\d{1,2}:\d{2}))/i
      );

      // –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–±–æ—Ç–µ
      const fullText = norm(card.textContent || '');
      
      // –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç—É—Å–æ–≤
      const jobSearchStatus = fullText.match(/(–∞–∫—Ç–∏–≤–Ω–æ\s+–∏—â[–∞—É–µ—ã—É]|–∏—â[–∞—É–µ—ã—É]\s+—Ä–∞–±–æ—Ç—É|–∞–∫—Ç–∏–≤–µ–Ω|–≥–æ—Ç–æ–≤\s+–∫\s+—Ä–∞–±–æ—Ç–µ|—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é\s+–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)/i)?.[0] || '';
      
      // –ò—â–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –±—ã—Å—Ç—Ä–æ–º—É –Ω–∞—á–∞–ª—É —Ä–∞–±–æ—Ç—ã  
      const readyToStart = fullText.match(/(–≥–æ—Ç–æ–≤\s+(?:–≤—ã–π—Ç–∏|–ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å|–Ω–∞—á–∞—Ç—å)?\s*(?:–∑–∞–≤—Ç—Ä–∞|—Å–µ–≥–æ–¥–Ω—è|–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ|—Å—Ä–∞–∑—É)|–º–æ–≥—É\s+–ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å|–Ω–∞—á–Ω[—É—ã]|–≥–æ—Ç–æ–≤\s+(?:–∑–∞–≤—Ç—Ä–∞|—Å–µ–≥–æ–¥–Ω—è|—Å—Ä–∞–∑—É))/i)?.[0] || '';

      const rec = {
        candidate_name_web: norm(q(card, '[data-marker="cv-snippet/title"]')?.textContent),
        city_web:           norm(q(card, '[data-marker="cv-snippet/address"]')?.textContent),
        link: link, resume_id: rid,
        purchased_at_web: purchasedRaw,
        updated_at_web:   updatedRaw,
        photo_url_web:     q(card, 'img[src]')?.src || '',
        job_search_status_web: jobSearchStatus,
        ready_to_start_web: readyToStart
      };

      const key = rec.resume_id || rec.link || rec.candidate_name_web;
      if (key && !seen.has(key)) { seen.add(key); out.push(rec); }
    }
    return out;
  }
"""

# ========== –†—É—Å—Å–∫–∏–µ –¥–∞—Ç—ã ==========
RU_MONTHS = {
    "—è–Ω–≤–∞—Ä—è":1,"—Ñ–µ–≤—Ä–∞–ª—è":2,"–º–∞—Ä—Ç–∞":3,"–∞–ø—Ä–µ–ª—è":4,"–º–∞—è":5,"–∏—é–Ω—è":6,
    "–∏—é–ª—è":7,"–∞–≤–≥—É—Å—Ç–∞":8,"—Å–µ–Ω—Ç—è–±—Ä—è":9,"–æ–∫—Ç—è–±—Ä—è":10,"–Ω–æ—è–±—Ä—è":11,"–¥–µ–∫–∞–±—Ä—è":12,
    "—è–Ω–≤":1,"—Ñ–µ–≤":2,"–º–∞—Ä":3,"–∞–ø—Ä":4,"–º–∞–π":5,"–º–∞—è":5,"–∏—é–Ω":6,"–∏—é–ª":7,
    "–∞–≤–≥":8,"—Å–µ–Ω":9,"—Å–µ–Ω—Ç":9,"–æ–∫—Ç":10,"–Ω–æ—è":11,"–¥–µ–∫":12,
    "—è–Ω–≤.":1,"—Ñ–µ–≤.":2,"–º–∞—Ä.":3,"–∞–ø—Ä.":4,"–∏—é–Ω.":6,"–∏—é–ª.":7,"–∞–≤–≥.":8,"—Å–µ–Ω.":9,"—Å–µ–Ω—Ç.":9,"–æ–∫—Ç.":10,"–Ω–æ—è.":11,"–¥–µ–∫.":12,
}

def _normalize_ru_dt_string(s: str) -> str:
    s = (s or "").lower().replace("\u00a0"," ").replace("—ë","–µ")
    s = re.sub(r"[¬∑‚Ä¢]\s*$","", s).strip()
    s = re.sub(r"^(–∫—É–ø–ª–µ–Ω[–æ–∞]?|–æ–±–Ω–æ–≤–ª–µ–Ω[–æ–∞]?|—É–¥–∞–ª–µ–Ω[–æ–∞]?|—Å–æ–∑–¥–∞–Ω[–æ–∞]?|–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω[–æ–∞]?|—Ä–∞–∑–º–µ—â–µ–Ω[–æ–∞]?)\s+","", s)
    s = re.sub(r"\s+\d{4}\s*(?:–≥\.?|–≥–æ–¥–∞)$","", s)
    return s.strip()

def parse_ru_dt(s: str, now: datetime | None = None) -> pd.Timestamp:
    if not s:
        return pd.NaT
    s_norm = _normalize_ru_dt_string(s)
    now = now or datetime.now()

    m = re.search(r"(—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞)\s*–≤\s*(\d{1,2})\s*:\s*(\d{2})", s_norm)
    if m:
        tag, hh, mm = m.groups()
        dt = now.replace(hour=int(hh), minute=int(mm), second=0, microsecond=0)
        if tag == "–≤—á–µ—Ä–∞":
            dt -= timedelta(days=1)
        return pd.Timestamp(dt.replace(tzinfo=None))

    text = s_norm.lower().replace("\u00a0", " ")
    m = re.search(r"(\d{1,2})\s+([–∞-—è\.]+)(?:\s+(\d{4}))?\s+–≤\s+(\d{1,2}):(\d{2})", text)
    if m:
        d, mon_word, year_str, hh, mm = m.groups()
        mon = RU_MONTHS.get(mon_word, RU_MONTHS.get(mon_word.rstrip(".")))
        if not mon:
            return pd.NaT
        year = int(year_str) if year_str else (now.year - (1 if mon > now.month else 0))
        try:
            base = datetime(year, int(mon), int(d), int(hh), int(mm))
            return pd.Timestamp(base)
        except Exception:
            return pd.NaT

    return pd.NaT

# ========== STOPLIST (–∂—ë—Å—Ç–∫–æ: C:\\ManekiNeko\\AVITO_API\\output) ==========
STOPLIST_DIR = Path(r"C:\\ManekiNeko\\AVITO_API\\output").resolve()

_FIO_PATTERNS = [
    r"\b—Ñ\.?–∏\.?–æ\.?\b", r"\b—Ñ–∏–æ\b", r"\b–∏–º—è\b", r"\b—Ñ–∞–º–∏–ª", r"–∫–∞–Ω–¥–∏–¥–∞—Ç", r"—Å–æ–∏—Å–∫–∞—Ç–µ–ª", r"applicant", r"name", r"full\s*name"
]
_PHONE_PATTERNS = [r"—Ç–µ–ª", r"phone", r"–Ω–æ–º–µ—Ä", r"mobile", r"mob"]
_COMMENT_PATTERNS = [r"–ø–æ–ª–Ω—ã–π\s*–∫–æ–º–º–µ–Ω—Ç", r"–ø–æ–ª–Ω—ã–π\s*–∫–æ–º–º–µ–Ω—Ç–∞—Ä", r"comment", r"–∫–æ–º–º–µ–Ω—Ç", r"–∑–∞–º–µ—á–∞–Ω–∏", r"–ø—Ä–∏–º–µ—á–∞–Ω"]

_DEF_COLS = {"phone": "–¢–µ–ª–µ—Ñ–æ–Ω", "fio": "–§–ò–û", "comment": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"}

def _clean_phone_series(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.replace(r"\D", "", regex=True)
    s = s.str.replace(r"^8(?=\d{10}$)", "7", regex=True)
    mask10 = s.str.match(r"^\d{10}$")
    s.loc[mask10] = "7" + s[mask10]
    return s

def _find_col(cols: list[str], patterns: list[str]) -> str | None:
    low = [c.lower().strip() for c in cols]
    for p in patterns:
        rx = re.compile(p, re.IGNORECASE)
        for i, name in enumerate(low):
            if rx.search(name):
                return cols[i]
    return None


def build_stoplist_from_output() -> tuple[pd.DataFrame, dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (stoplist_df, file_stats)
    –≥–¥–µ file_stats = {"filename": count_records, ...}
    """
    rows: list[pd.DataFrame] = []
    file_stats = {}
    if not STOPLIST_DIR.exists():
        return pd.DataFrame(columns=[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]), {}

    SHEET_NAME = "–°—Ç–æ–ø–ª–∏—Å—Ç_—Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"
    EXPECTED_PHONE = "—Ç–µ–ª–µ—Ñ–æ–Ω"
    EXPECTED_FIO = "—Ñ–∏–æ"
    EXPECTED_COMMENT_FULL = "–ø–æ–ª–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"

    for fp in STOPLIST_DIR.glob("*.xlsx"):
        if fp.name.startswith("~$"):
            continue
        try:
            xl = pd.ExcelFile(fp, engine="openpyxl")
            if SHEET_NAME not in xl.sheet_names:
                continue

            df = xl.parse(SHEET_NAME)
            if df.empty:
                continue

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            low2orig = {str(c).strip(): c for c in df.columns}
            lowmap = {k.lower(): v for k, v in low2orig.items()}

            phone_col   = lowmap.get(EXPECTED_PHONE)
            fio_col     = lowmap.get(EXPECTED_FIO)
            comment_col = lowmap.get(EXPECTED_COMMENT_FULL)

            # –ë–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ ‚Äî —ç—Ç–æ –Ω–µ —Å—Ç–æ–ø–ª–∏—Å—Ç
            if not phone_col:
                continue

            sub = pd.DataFrame()
            sub[_DEF_COLS["phone"]] = _clean_phone_series(df[phone_col])
            sub[_DEF_COLS["fio"]] = df[fio_col] if fio_col else ""
            # –í–Ω—É—Ç—Ä–∏ —Å–∏—Å—Ç–µ–º—ã ¬´–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π¬ª ‚Äî —ç—Ç–æ —Ç–æ, —á—Ç–æ –Ω–∞ –ª–∏—Å—Ç–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è ¬´–ü–æ–ª–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π¬ª
            sub[_DEF_COLS["comment"]] = df[comment_col] if comment_col else ""
            sub["–§–∞–π–ª"], sub["–õ–∏—Å—Ç"] = fp.name, SHEET_NAME

            # –æ—Ç–±—Ä–æ—Å–∏–º –ø—É—Å—Ç—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            sub = sub[sub[_DEF_COLS["phone"]].astype(str).str.len() > 0]
            if not sub.empty:
                file_stats[fp.name] = len(sub)
                rows.append(sub[[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]])
        except Exception:
            continue

    if not rows:
        return pd.DataFrame(columns=[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]), {}

    all_df = pd.concat(rows, ignore_index=True)
    all_df[_DEF_COLS["phone"]] = _clean_phone_series(all_df[_DEF_COLS["phone"]])

    # –î–µ–¥—É–ø –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É: –æ—Å—Ç–∞–≤–∏–º –∑–∞–ø–∏—Å—å —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –¥–ª–∏–Ω–æ–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
    try:
        all_df["_clen"] = all_df[_DEF_COLS["comment"]].astype(str).map(len)
        all_df = all_df.sort_values([_DEF_COLS["phone"], "_clen"], ascending=[True, False])
        all_df = all_df.drop_duplicates(subset=[_DEF_COLS["phone"]], keep="first")
        all_df = all_df.drop(columns=["_clen"])
    except Exception:
        all_df = all_df.drop_duplicates(subset=[_DEF_COLS["phone"]], keep="first")

    return all_df.reset_index(drop=True), file_stats

# ========== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –≤–µ–±-—Ñ—É–Ω–∫—Ü–∏–∏ ==========

def await_clear_cookies_except_auth(context):
    """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—É–∫–æ–≤ –∫—Ä–æ–º–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫—É–∫–∏
        cookies = context.cookies()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—É–∫–∏ (–æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç session, auth, token, user)
        auth_keywords = ['session', 'auth', 'token', 'user', 'login', 'sid', 'ssid']
        auth_cookies = []
        other_cookies = []
        
        for cookie in cookies:
            cookie_name = cookie.get('name', '').lower()
            is_auth_cookie = any(keyword in cookie_name for keyword in auth_keywords)
            
            if is_auth_cookie:
                auth_cookies.append(cookie)
            else:
                other_cookies.append(cookie)
        
        print(f"üç™ –ù–∞–π–¥–µ–Ω–æ –∫—É–∫–æ–≤: –≤—Å–µ–≥–æ {len(cookies)}, –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö {len(auth_cookies)}, –ø—Ä–æ—á–∏—Ö {len(other_cookies)}")
        
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –∫—É–∫–∏
        context.clear_cookies()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫—É–∫–∏
        if auth_cookies:
            context.add_cookies(auth_cookies)
            print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(auth_cookies)} –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∫—É–∫–æ–≤")
        
        print(f"üßπ –£–¥–∞–ª–µ–Ω–æ {len(other_cookies)} –ª–∏—à–Ω–∏—Ö –∫—É–∫–æ–≤")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—É–∫–æ–≤: {e}")

def save_as_mhtml(page, out_path: Path):
    s = page.context.new_cdp_session(page)
    s.send("Page.enable")
    data = s.send("Page.captureSnapshot", {"format": "mhtml"})["data"]
    out_path.write_text(data, encoding="utf-8")
    return out_path

def goto_resilient(page, url, expect_pattern, attempts=3):
    for _ in range(attempts):
        try: page.goto(url, wait_until="commit", timeout=NAV_TIMEOUT)
        except PwError: pass
        try:
            page.wait_for_url(expect_pattern, wait_until="domcontentloaded", timeout=30_000)
            return True
        except PwError:
            try: page.goto(HOME_URL, wait_until="domcontentloaded", timeout=30_000)
            except PwError: pass
    return False

def get_control_count_from_favorites(page):
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É —Ä–µ–∑—é–º–µ –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ"""
    print("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ...")
    
    try:
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ —Å —Ä–µ–∑—é–º–µ
        favorites_url = "https://www.avito.ru/favorites?categoryId=112"
        page.goto(favorites_url, wait_until="domcontentloaded", timeout=30_000)
        time.sleep(5)  # –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–∏—Å–∫–∞ —Ü–∏—Ñ—Ä—ã
        count_text = page.evaluate("""
            () => {
                console.log('–ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã...');
                
                // –°–ø–æ—Å–æ–± 1: –ò—â–µ–º —Ç–µ–∫—Å—Ç "–†–µ–∑—é–º–µ" –∏ —Ä—è–¥–æ–º —Å –Ω–∏–º —Ü–∏—Ñ—Ä—É
                const allText = document.body.textContent || '';
                console.log('–í–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã:', allText.substring(0, 500));
                
                let match = allText.match(/—Ä–µ–∑—é–º–µ[\\s\\(\\)]*([0-9]+)/gi);
                if (match) {
                    console.log('–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ø–æ—Å–æ–±–æ–º 1:', match);
                    const numbers = match.map(m => parseInt(m.match(/([0-9]+)/)[1]));
                    if (numbers.length > 0) {
                        return Math.max(...numbers); // –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É
                    }
                }
                
                // –°–ø–æ—Å–æ–± 2: –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–∏—Ñ—Ä–∞–º–∏
                const elements = Array.from(document.querySelectorAll('*'));
                for (const el of elements) {
                    const text = (el.textContent || '').trim();
                    
                    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä—è–¥–æ–º —Å–ª–æ–≤–æ "—Ä–µ–∑—é–º–µ" –∏ —Ü–∏—Ñ—Ä–∞
                    if (/—Ä–µ–∑—é–º–µ/i.test(text)) {
                        const numMatch = text.match(/([0-9]+)/);
                        if (numMatch) {
                            console.log('–ù–∞–π–¥–µ–Ω–æ —Å–ø–æ—Å–æ–±–æ–º 2:', text, numMatch[1]);
                            return parseInt(numMatch[1]);
                        }
                    }
                }
                
                // –°–ø–æ—Å–æ–± 3: –ò—â–µ–º span, div —Å –∫–ª–∞—Å—Å–∞–º–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ count, number, badge
                const countElements = document.querySelectorAll('[class*="count"], [class*="number"], [class*="badge"], [class*="total"]');
                for (const el of countElements) {
                    const text = (el.textContent || '').trim();
                    const numMatch = text.match(/^([0-9]+)$/);
                    if (numMatch) {
                        const num = parseInt(numMatch[1]);
                        if (num > 10) { // –†–∞–∑—É–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —ç—Ç–æ –Ω–µ –º–µ–ª–∫–∞—è —Ü–∏—Ñ—Ä–∞
                            console.log('–ù–∞–π–¥–µ–Ω–æ —Å–ø–æ—Å–æ–±–æ–º 3:', text, num);
                            return num;
                        }
                    }
                }
                
                // –°–ø–æ—Å–æ–± 4: –ò—â–µ–º –≤—Å–µ —á–∏—Å–ª–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª—å—à–µ–µ —Ä–∞–∑—É–º–Ω–æ–µ
                const allNumbers = allText.match(/\\b([0-9]{2,5})\\b/g);
                if (allNumbers) {
                    const numbers = allNumbers.map(n => parseInt(n)).filter(n => n > 50 && n < 50000);
                    if (numbers.length > 0) {
                        const maxNum = Math.max(...numbers);
                        console.log('–ù–∞–π–¥–µ–Ω–æ —Å–ø–æ—Å–æ–±–æ–º 4 (–º–∞–∫—Å —á–∏—Å–ª–æ):', maxNum);
                        return maxNum;
                    }
                }
                
                // –°–ø–æ—Å–æ–± 5: –ü–æ–∏—Å–∫ –≤ URL –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏–ª–∏ data –∞—Ç—Ä–∏–±—É—Ç–∞—Ö
                const dataElements = document.querySelectorAll('[data-count], [data-total], [data-number]');
                for (const el of dataElements) {
                    const count = el.getAttribute('data-count') || el.getAttribute('data-total') || el.getAttribute('data-number');
                    if (count && /^[0-9]+$/.test(count)) {
                        console.log('–ù–∞–π–¥–µ–Ω–æ —Å–ø–æ—Å–æ–±–æ–º 5 (data –∞—Ç—Ä–∏–±—É—Ç—ã):', count);
                        return parseInt(count);
                    }
                }
                
                console.log('–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –æ–¥–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º');
                return 0;
            }
        """)
        
        if count_text and count_text > 0:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞: {count_text}")
            return count_text
        else:
            print("‚ö†Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            
            # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            print("üìã –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∞. –ù–∞–π–¥–∏—Ç–µ —Ü–∏—Ñ—Ä—É —Ä—è–¥–æ–º —Å '–†–µ–∑—é–º–µ'")
            user_input = input("–í–≤–µ–¥–∏—Ç–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É –≤—Ä—É—á–Ω—É—é (–∏–ª–∏ Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
            
            if user_input.isdigit():
                control_count = int(user_input)
                print(f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–ª –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É: {control_count}")
                return control_count
            else:
                print("‚ö†Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ –Ω–µ –∑–∞–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                return 0
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã: {e}")
        return 0

def robust_scroll_aggressive(page, target_count: int | None = None) -> int:
    """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª–∏–Ω–≥ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫"""
    print(f"üöÄ –ù–∞—á–∞–ª–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ —Ü–µ–ª–∏: {target_count}")
    
    unique_links = set()
    max_attempts = 200  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
    attempts = 0
    no_progress_count = 0
    
    while attempts < max_attempts:
        attempts += 1
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Å—Å—ã–ª–∫–∏
        current_records = page.evaluate(EXTRACT_JS) or []
        current_links = set()
        
        for record in current_records:
            link = record.get('link', '')
            resume_id = record.get('resume_id', '')
            if link:
                current_links.add(link)
            elif resume_id:
                current_links.add(f"resume_{resume_id}")
        
        # v15: –ü–†–ò–û–†–ò–¢–ï–¢ #1 - –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–æ–ø-—Ç—Ä–∏–≥–≥–µ—Ä (–≥–ª–∞–≤–Ω—ã–π)
        for record in current_records:
            link = record.get('link', '')
            if link == STOP_TRIGGER_URL:
                print(f"üõë –°–¢–û–ü-–¢–†–ò–ì–ì–ï–†! –ù–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è —Å—Å—ã–ª–∫–∞: {STOP_TRIGGER_URL}")
                print(f"üìä –°–æ–±—Ä–∞–Ω–æ {len(unique_links)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—é–º–µ –¥–æ —Ç—Ä–∏–≥–≥–µ—Ä–∞")
                return len(unique_links)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
        old_count = len(unique_links)
        unique_links.update(current_links)
        new_count = len(unique_links)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        if new_count > old_count:
            no_progress_count = 0
            print(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {new_count}/{target_count or '‚àû'} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—é–º–µ (–ø–æ–ø—ã—Ç–∫–∞ {attempts})")
        else:
            no_progress_count += 1
            
        # –ü–†–ò–û–†–ò–¢–ï–¢ #2 - –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç (–≤—Ç–æ—Ä–∏—á–Ω—ã–π)
        if target_count and new_count >= target_count:
            print(f"üéØ –õ–∏–º–∏—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç! –ù–∞–π–¥–µ–Ω–æ {new_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—é–º–µ")
            return new_count
            
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ, –∑–∞–≤–µ—Ä—à–∞–µ–º
        if no_progress_count >= 20:
            print(f"‚èπÔ∏è –ù–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ {no_progress_count} –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–¥—Ä—è–¥. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
            break
        
        # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Å–∫—Ä–æ–ª–ª–∏–Ω–≥
        try:
            # –ë—ã—Å—Ç—Ä—ã–π —Å–∫—Ä–æ–ª–ª –≤ –∫–æ–Ω–µ—Ü
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(0.3)
            
            # –ö–ª–∏–∫ –Ω–∞ –∫–Ω–æ–ø–∫–∏ "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â–µ"
            page.evaluate("""
                const buttons = Array.from(document.querySelectorAll('button, a')).filter(b => 
                    /(–ø–æ–∫–∞–∑–∞—Ç[—å—ä]\\s*–µ—â[–µ—ë]|–ø–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ|–µ—â—ë|–∑–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë)/i.test(b.textContent)
                );
                buttons.forEach(b => {
                    if (!b.disabled && !b.getAttribute('aria-disabled')) {
                        b.click();
                    }
                });
            """)
            time.sleep(0.5)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–∫—Ä–æ–ª–ª –∫–æ–ª–µ—Å–æ–º
            page.mouse.wheel(0, 2000)
            time.sleep(0.2)
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥–µ: {e}")
            
    print(f"üèÅ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—é–º–µ: {len(unique_links)}")
    return len(unique_links)

def robust_scroll(page, need_count: int | None = None) -> int:
    try:
        count1 = page.evaluate(ROBUST_SCROLL_LIMIT_JS, need_count)
    except Exception:
        count1 = 0

    last_h, still = 0, 0
    for _ in range(MAX_WHEEL_STEPS):
        try: page.mouse.wheel(0, 1600)
        except Exception: pass
        time.sleep(WHEEL_DELAY_SEC)
        try: h = page.evaluate("Math.max(document.body.scrollHeight, document.documentElement.scrollHeight)")
        except Exception: h = last_h
        if h <= last_h:
            still += 1
            if still >= 6: break
        else:
            still = 0; last_h = h
        if need_count is not None:
            try:
                cur = int(page.evaluate(COUNT_CARDS_JS))
                if cur >= int(need_count):
                    break
            except Exception:
                pass

    quiet = 0
    while quiet < NETWORK_IDLE_GRACE:
        try:
            page.wait_for_response(
                lambda r: ("avito.ru" in r.url) and r.status == 200 and
                          (getattr(r.request, "resource_type", None) in ("xhr","fetch")),
                timeout=WAIT_RESP_TIMEOUT_MS
            )
            quiet = 0
        except Exception:
            quiet += 1

    try:
        count2 = int(page.evaluate(COUNT_CARDS_JS))
    except Exception:
        count2 = count1
    return min(count2, need_count) if need_count else max(count1, count2)

# ========== ENRICH (API): –§–ò–û/–∫–æ–Ω—Ç–∞–∫—Ç—ã/is_purchased/update_time ==========

def _salary_to_text(sal):
    if sal is None:
        return ""
    if isinstance(sal, (int, float)):
        return str(int(sal))
    if isinstance(sal, dict):
        lo = sal.get("from")
        hi = sal.get("to")
        cur = sal.get("currency", "")
        rng = "" if (lo is None and hi is None) else f"{lo or ''}‚Äì{hi or ''}"
        return (rng + (f" {cur}" if cur else "")).strip()
    return str(sal)


def enrich_one(resume_id: str, tz_target) -> dict:
    open_js = get_resume_open_json(resume_id)
    paid_js = get_resume_paid_contacts_json(resume_id)

    phone = email = chat_id = ""
    fio = ""
    first_name = last_name = patronymic = ""

    if paid_js:
        fio = (paid_js.get("name") or "")[:256].strip()
        fn = paid_js.get("full_name") or {}
        first_name  = str(fn.get("first_name") or "")
        last_name   = str(fn.get("last_name") or "")
        patronymic  = str(fn.get("patronymic") or "")
        if not fio:
            fio = " ".join(x for x in (last_name, first_name, patronymic) if x).strip()
        for c in (paid_js.get("contacts") or []):
            t = str(c.get("type") or "").lower()
            v = str(c.get("value") or "")
            if   t == "phone":   phone = v
            elif t in ("e-mail", "email"):  email = v
            elif t == "chat_id": chat_id = v

    # <-- –ù–û–í–û–ï v11: –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞ —á–∞—Ç–∞ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON —Ñ–∞–π–ª–∞
    chat_status = ChatStatus.NO_CHAT.value
    last_message_direction = None
    last_message_text = None
    
    if chat_id and CHATS_DATA:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ API –≤—ã–∑–æ–≤–æ–≤
            chat_data = CHATS_DATA.get(chat_id)
            if chat_data:
                status, direction, text = analyze_chat_from_json(chat_data)
                chat_status = status
                last_message_direction = direction
                last_message_text = text[:200] if text else None  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                print(f"‚úÖ Chat {chat_id}: {status} | {direction}")
            else:
                print(f"‚ö†Ô∏è  Chat {chat_id} not found in loaded data")
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ "–Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö" —á–∞—Ç–æ–≤
                global NOT_FOUND_CHATS
                if chat_id not in NOT_FOUND_CHATS:
                    NOT_FOUND_CHATS.append(chat_id)
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∫ "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"
                chat_status = ChatStatus.NO_MESSAGES_SENT.value
        except Exception as e:
            print(f"‚ö†Ô∏è  chat status analysis failed for {chat_id}: {e}")

    is_purchased_api = bool(open_js.get("is_purchased")) if isinstance(open_js, dict) else False
    update_time_api_raw = str(open_js.get("update_time") or "") if isinstance(open_js, dict) else ""

    try:
        ut = pd.to_datetime(update_time_api_raw, errors="coerce", utc=True)
        if pd.isna(ut):
            update_time_api = pd.NaT
        else:
            local = ut.tz_convert(tz_target)
            update_time_api = local.tz_localize(None)
    except Exception:
        update_time_api = pd.NaT

    desired_title_api   = str(open_js.get("title") or "")
    salary_expected_api = _salary_to_text(open_js.get("salary"))
    
    return {
        "fio_api": fio,
        "first_name_api": first_name,
        "last_name_api": last_name,
        "patronymic_api": patronymic,
        "phone_api": phone,
        "email_api": email,
        "chat_id_api": chat_id,      # –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ
        "is_purchased_api": is_purchased_api,
        "update_time_api": update_time_api,
        "updated_at_api": update_time_api,  # –∫–æ–ø–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—è–¥–æ–º —Å updated_at_web
        "update_time_api_raw": update_time_api_raw,
        "desired_title_api": desired_title_api,
        "salary_expected_api": salary_expected_api,
        # –ù–æ–≤—ã–µ –ø–æ–ª—è v11 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–æ–≤
        "chat_status": chat_status,
        "last_message_direction": last_message_direction,
        "last_message_text": last_message_text,
        "json_open": json.dumps(open_js, ensure_ascii=False),
        "json_paid": json.dumps(paid_js, ensure_ascii=False),
    }


# ========== –í–≤–æ–¥ –ª–∏–º–∏—Ç–∞/TZ ==========

def _parse_limit_arg(argv: list[str]) -> int | None:
    try:
        if "--limit" in argv:
            i = argv.index("--limit")
            return max(0, int(argv[i+1]))
        if "-n" in argv:
            i = argv.index("-n")
            return max(0, int(argv[i+1]))
    except Exception:
        pass
    return None

def _parse_tz_arg(argv: list[str]) -> str | None:
    try:
        if "--tz" in argv:
            i = argv.index("--tz")
            return argv[i+1]
        if "-t" in argv:
            i = argv.index("-t")
            return argv[i+1]
    except Exception:
        pass
    return None

def _parse_threads_arg(argv: list[str]) -> int:
    """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    try:
        if "--threads" in argv:
            i = argv.index("--threads")
            return max(1, min(20, int(argv[i+1])))  # –û—Ç 1 –¥–æ 20 –ø–æ—Ç–æ–∫–æ–≤
        if "-j" in argv:
            i = argv.index("-j")
            return max(1, min(20, int(argv[i+1])))
    except Exception:
        pass
    return 8  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 8 –ø–æ—Ç–æ–∫–æ–≤


def ask_limit_from_user() -> int | None:
    s = input("–°–∫–æ–ª—å–∫–æ —Ä–µ–∑—é–º–µ —Å–æ–±—Ä–∞—Ç—å? –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ 'all' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: all): ").strip().lower()
    if not s or s in ("all", "–≤—Å–µ"):
        return None
    try:
        n = int(s)
        return n if n > 0 else None
    except Exception:
        print("–ù–µ –ø–æ–Ω—è–ª –≤–≤–æ–¥. –ë—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω–æ '–≤—Å–µ'.")
        return None


def enrich_resume_batch(resume_ids: list[str], tz_target, max_workers: int = 8) -> dict[str, dict]:
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ —á–µ—Ä–µ–∑ ThreadPoolExecutor.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {resume_id: enriched_data}
    """
    results = {}
    
    def enrich_single(resume_id: str) -> tuple[str, dict]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ–∑—é–º–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        try:
            data = enrich_one(resume_id, tz_target)
            return resume_id, data
        except Exception as e:
            print(f"‚ö†Ô∏è  API enrich failed for {resume_id}: {e}")
            return resume_id, {}
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(resume_ids)} —Ä–µ–∑—é–º–µ –≤ {max_workers} –ø–æ—Ç–æ–∫–æ–≤...")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        future_to_id = {executor.submit(enrich_single, rid): rid for rid in resume_ids}
        
        completed = 0
        for future in as_completed(future_to_id):
            resume_id, data = future.result()
            results[resume_id] = data
            completed += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ä–µ–∑—é–º–µ
            if completed % 10 == 0 or completed == len(resume_ids):
                print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {completed}/{len(resume_ids)} —Ä–µ–∑—é–º–µ ({completed/len(resume_ids)*100:.1f}%)")
    
    print(f"üéâ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—é–º–µ")
    return results


def is_excluded_region(region_api: str, city_api: str, city_web: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É.
    –ò—Å–∫–ª—é—á–∞–µ–º: –ß–µ—á–Ω—è, –î–∞–≥–µ—Å—Ç–∞–Ω, –ò–Ω–≥—É—à–µ—Ç–∏—è, –¢—É–≤–∞
    """
    excluded_regions = {
        "—á–µ—á–µ–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞", "—á–µ—á–Ω—è", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ —á–µ—á–Ω—è",
        "–¥–∞–≥–µ—Å—Ç–∞–Ω", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ –¥–∞–≥–µ—Å—Ç–∞–Ω", 
        "–∏–Ω–≥—É—à–µ—Ç–∏—è", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ –∏–Ω–≥—É—à–µ—Ç–∏—è",
        "—Ç—É–≤–∞", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ —Ç—ã–≤–∞", "—Ç—ã–≤–∞"
    }
    
    excluded_cities = {
        "–≥—Ä–æ–∑–Ω—ã–π", "–º–∞—Ö–∞—á–∫–∞–ª–∞", "–Ω–∞–∑—Ä–∞–Ω—å", "–∫—ã–∑—ã–ª", "–º–∞–≥–∞—Å"
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–≥–∏–æ–Ω –∏–∑ API
    if region_api:
        region_lower = region_api.lower().strip()
        if any(excluded in region_lower for excluded in excluded_regions):
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ä–æ–¥ –∏–∑ API
    if city_api:
        city_lower = city_api.lower().strip()
        if city_lower in excluded_cities:
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ä–æ–¥ –∏–∑ web-–¥–∞–Ω–Ω—ã—Ö (fallback)
    if city_web:
        city_lower = city_web.lower().strip()
        if city_lower in excluded_cities:
            return True
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –≤ —Å—Ç—Ä–æ–∫–µ –≥–æ—Ä–æ–¥–∞ (—á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç "–≥. –ì—Ä–æ–∑–Ω—ã–π, –ß–µ—á–µ–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞")
        if any(excluded in city_lower for excluded in excluded_regions):
            return True
    
    return False


def create_today_sheet(df: pd.DataFrame, stop_df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç '–Ω–∞_—Å–µ–≥–æ–¥–Ω—è' —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π:
    1. updated_at_web –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    2. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É (–ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É)
    3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º (–ß–µ—á–Ω—è, –î–∞–≥–µ—Å—Ç–∞–Ω, –ò–Ω–≥—É—à–µ—Ç–∏—è, –¢—É–≤–∞)
    """
    if df.empty:
        return pd.DataFrame()
    
    # 1. –§–∏–ª—å—Ç—Ä –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞)
    cutoff_time = datetime.now() - timedelta(hours=24)
    
    today_df = df.copy()
    if "updated_at_web" in today_df.columns:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        today_df["updated_at_web"] = pd.to_datetime(today_df["updated_at_web"], errors="coerce")
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        mask_recent = today_df["updated_at_web"] >= cutoff_time
        today_df = today_df[mask_recent]
    
    if today_df.empty:
        return pd.DataFrame()
    
    # 2. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É (—Ç–µ–ª–µ—Ñ–æ–Ω—ã)
    if not stop_df.empty and "phone_api" in today_df.columns:
        today_df["_phone_clean"] = _clean_phone_series(today_df["phone_api"]).fillna("")
        stop_phones = set(_clean_phone_series(stop_df[_DEF_COLS["phone"]]).fillna(""))
        stop_phones.discard("")  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
        
        if stop_phones:
            mask_not_in_stoplist = ~today_df["_phone_clean"].isin(stop_phones)
            today_df = today_df[mask_not_in_stoplist]
        
        today_df = today_df.drop(columns=["_phone_clean"], errors="ignore")
    
    if today_df.empty:
        return pd.DataFrame()
    
    # 3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ city_web, —Ç–∞–∫ –∫–∞–∫ API –ø–æ–ª—è —É–¥–∞–ª–µ–Ω—ã)
    mask_not_excluded_region = ~today_df.apply(
        lambda row: is_excluded_region(
            "",  # region_api —É–¥–∞–ª–µ–Ω–æ
            "",  # city_api —É–¥–∞–ª–µ–Ω–æ
            row.get("city_web", "")
        ), 
        axis=1
    )
    today_df = today_df[mask_not_excluded_region]
    
    return today_df.reset_index(drop=True)


def create_not_contacted_sheet(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç '–ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏' —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏ —É –∫–æ—Ç–æ—Ä—ã—Ö chat_status = "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"
    –í–∫–ª—é—á–∞–µ—Ç –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–∞–∂–µ –∏–∑ —Å—Ç–æ–ø-–ª–∏—Å—Ç–∞) –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫—É –Ω–∞ —á–∞—Ç
    """
    if df.empty or "chat_status" not in df.columns:
        return pd.DataFrame()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ—Ö, –∫–æ–º—É –Ω–µ –ø–∏—Å–∞–ª–∏
    not_contacted = df[df["chat_status"] == ChatStatus.NO_MESSAGES_SENT.value].copy()
    
    if not_contacted.empty:
        return pd.DataFrame()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —á–∞—Ç
    def create_chat_url(row):
        chat_id = row.get("chat_id_api", "")
        if chat_id and str(chat_id).strip() and str(chat_id) != "nan":
            return f"https://www.avito.ru/profile/messenger/{chat_id}"
        return ""
    
    not_contacted["chat_url"] = not_contacted.apply(create_chat_url, axis=1)
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø–æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–±–æ—Ç–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º job_search_status_web)
    status_priority = {
        "–∞–∫—Ç–∏–≤–Ω–æ –∏—â—É —Ä–∞–±–æ—Ç—É": 1,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –∑–∞–≤—Ç—Ä–∞": 2,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ 2-—Ö –Ω–µ–¥–µ–ª—å": 3,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞": 4,
        "–±—É–¥—É –∏—Å–∫–∞—Ç—å —Ä–∞–±–æ—Ç—É —á–µ—Ä–µ–∑ 2-3 –º–µ—Å—è—Ü–∞": 5,
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ job_search_status_web
    if "job_search_status_web" in not_contacted.columns:
        not_contacted["_status_priority"] = not_contacted["job_search_status_web"].str.lower().map(status_priority).fillna(6)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É —Å—Ç–∞—Ç—É—Å–∞, –ø–æ—Ç–æ–º –ø–æ –¥–∞—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        sort_cols = ["_status_priority"]
        if "updated_at_web" in not_contacted.columns:
            sort_cols.append("updated_at_web")
        
        not_contacted = not_contacted.sort_values(sort_cols, ascending=[True, False])
        
        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
        not_contacted = not_contacted.drop(columns=["_status_priority"], errors="ignore")
    
    return not_contacted.reset_index(drop=True)


def create_not_found_chats_sheet(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç '–ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´' —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º–∏, —á—å–∏ chat_id –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ loaded data
    –≠—Ç–æ —Ç–µ, –∫–æ–º—É —Ç–æ—á–Ω–æ –Ω–µ –ø–∏—Å–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è. –£–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –Ω–æ–º–µ—Ä—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞.
    """
    global NOT_FOUND_CHATS
    
    if df.empty or not NOT_FOUND_CHATS:
        return pd.DataFrame()
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –ø–æ "–Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–º" chat_id
    not_found_df = df[df["chat_id_api"].isin(NOT_FOUND_CHATS)].copy()
    
    if not_found_df.empty:
        return pd.DataFrame()
    
    # –£–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –Ω–æ–º–µ—Ä—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (–±–µ—Ä–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –∑–∞–ø–∏—Å—å)
    if "phone_api" in not_found_df.columns and "updated_at_web" in not_found_df.columns:
        # –£–±–∏—Ä–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–∞
        not_found_df = not_found_df[not_found_df["phone_api"].notna() & (not_found_df["phone_api"] != "")]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
        not_found_df = not_found_df.sort_values("updated_at_web", ascending=False)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é (—Å–∞–º—É—é —Å–≤–µ–∂—É—é) –∑–∞–ø–∏—Å—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–ª–µ—Ñ–æ–Ω–∞
        not_found_df = not_found_df.drop_duplicates(subset=["phone_api"], keep="first")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —á–∞—Ç
    def create_chat_url(row):
        chat_id = row.get("chat_id_api", "")
        if chat_id and str(chat_id).strip() and str(chat_id) != "nan":
            return f"https://www.avito.ru/profile/messenger/{chat_id}"
        return ""
    
    not_found_df["chat_url"] = not_found_df.apply(create_chat_url, axis=1)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    not_found_df["–∏—Å—Ç–æ—á–Ω–∏–∫"] = "–ù–ï –ù–ê–ô–î–ï–ù –í API"
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø–æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–±–æ—Ç–µ
    status_priority = {
        "–∞–∫—Ç–∏–≤–Ω–æ –∏—â—É —Ä–∞–±–æ—Ç—É": 1,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –∑–∞–≤—Ç—Ä–∞": 2,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ 2-—Ö –Ω–µ–¥–µ–ª—å": 3,
        "–≥–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞": 4,
        "–±—É–¥—É –∏—Å–∫–∞—Ç—å —Ä–∞–±–æ—Ç—É —á–µ—Ä–µ–∑ 2-3 –º–µ—Å—è—Ü–∞": 5,
    }
    
    if "job_search_status_web" in not_found_df.columns:
        not_found_df["_status_priority"] = not_found_df["job_search_status_web"].str.lower().map(status_priority).fillna(6)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É —Å—Ç–∞—Ç—É—Å–∞, –ø–æ—Ç–æ–º –ø–æ –¥–∞—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        sort_cols = ["_status_priority"]
        if "updated_at_web" in not_found_df.columns:
            sort_cols.append("updated_at_web")
        
        not_found_df = not_found_df.sort_values(sort_cols, ascending=[True, False])
        
        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
        not_found_df = not_found_df.drop(columns=["_status_priority"], errors="ignore")
    
    return not_found_df.reset_index(drop=True)


def process_resumes_parallel(uniq: list, tz_target, num_threads: int) -> dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º API enrichment."""
    # ENRICH —á–µ—Ä–µ–∑ Avito API ‚Üí tz_target (–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û)
    resume_ids = [rec.get("resume_id") for rec in uniq if rec.get("resume_id")]
    resume_ids = [rid for rid in resume_ids if rid]  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
    
    if resume_ids:
        api_cache = enrich_resume_batch(resume_ids, tz_target, max_workers=num_threads)
    else:
        api_cache = {}
    
    return api_cache


# ========== MAIN ==========
def main():
    from openpyxl.utils import get_column_letter

    tz_name = _parse_tz_arg(sys.argv) or os.getenv("AVITO_TZ") or DEFAULT_TZ_NAME
    tz_target = _get_tz(tz_name)
    num_threads = _parse_threads_arg(sys.argv)

    limit = _parse_limit_arg(sys.argv)
    if limit is None:
        limit = ask_limit_from_user()

    print(f"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏: –ª–∏–º–∏—Ç={limit or '–≤—Å–µ'}, –ø–æ—Ç–æ–∫–æ–≤={num_threads}, —á–∞—Å–æ–≤–æ–π_–ø–æ—è—Å={tz_name}")
    print(f"üõë –°—Ç–æ–ø-—Ç—Ä–∏–≥–≥–µ—Ä (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç #1): {STOP_TRIGGER_URL}")
    print(f"üéØ –õ–∏–º–∏—Ç (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç #2): –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π ‚Üí –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ ‚Üí –±–µ–∑ –ª–∏–º–∏—Ç–∞")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    global CHATS_DATA, NOT_FOUND_CHATS
    CHATS_DATA = load_chats_from_api()
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(CHATS_DATA)} —á–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    USER_DATA_DIR.mkdir(parents=True, exist_ok=True)
    with sync_playwright() as p:
        context = p.chromium.launch_persistent_context(
            user_data_dir=str(USER_DATA_DIR),
            headless=False,
            viewport={"width": 1200, "height": 800},  # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
            args=[
                "--disable-blink-features=AutomationControlled", 
                "--no-sandbox",
                "--disable-background-timer-throttling",
                "--disable-backgrounding-occluded-windows",
                "--disable-renderer-backgrounding"
            ],
        )
        
        # –ö–∞—Ä—Ç–∏–Ω–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã (—É–±—Ä–∞–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É)
        
        context.set_default_timeout(NAV_TIMEOUT)
        context.set_default_navigation_timeout(NAV_TIMEOUT)
        page = context.new_page()
        
        # v15: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞—Å—à—Ç–∞–± –±—Ä–∞—É–∑–µ—Ä–∞ 45%
        page.evaluate("document.body.style.zoom = '0.45'")
        
        # –û—á–∏—Å—Ç–∫–∞ –∫—É–∫–æ–≤ –∫—Ä–æ–º–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö
        print("üßπ –û—á–∏—Å—Ç–∫–∞ –∫—É–∫–æ–≤ (–∫—Ä–æ–º–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö)...")
        await_clear_cookies_except_auth(context)

        try:
            page.goto(HOME_URL, wait_until="domcontentloaded")
        except PwError:
            pass

        input(f"\n–û—Ç–∫—Ä—ã–ª—Å—è –±—Ä–∞—É–∑–µ—Ä. –í–æ–π–¥–∏—Ç–µ –≤ Avito –∏ –Ω–∞–∂–º–∏—Ç–µ Enter –∑–¥–µ—Å—å...\n(–¢–µ–∫—É—â–∏–π TZ: {tz_name})\n–°—Ç–æ–ø–ª–∏—Å—Ç –∏–∑: {STOPLIST_DIR}\n")

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ
        control_count = get_control_count_from_favorites(page)
        print(f"üéØ –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ —Ä–µ–∑—é–º–µ –∏–∑ –∏–∑–±—Ä–∞–Ω–Ω–æ–≥–æ: {control_count}")
        
        # v15: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ª–∏–º–∏—Ç –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä–æ–π
        user_limit = _parse_limit_arg(sys.argv)  # –ü–æ–ª—É—á–∞–µ–º –∏–∑–Ω–∞—á–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        if user_limit is not None:
            print(f"üîí –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ª–∏–º–∏—Ç: {user_limit} (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É)")
            limit = user_limit
        elif control_count > 0:
            limit = control_count  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ü–∏—Ñ—Ä—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ª–∏–º–∏—Ç–∞
            print(f"üìä –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç –∏–∑ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ü–∏—Ñ—Ä—ã: {limit}")
        else:
            print(f"‚ö†Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Ü–∏—Ñ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–π –ª–∏–º–∏—Ç: {limit}")

        goto_resilient(page, TARGET_URL, "**/profile/paid-cvs*")
        total_cards_est = robust_scroll_aggressive(page, target_count=limit)

        records = page.evaluate(EXTRACT_JS) or []
        if limit is not None:
            records = records[:limit]

        # –¥–µ–¥—É–ø
        uniq, seen = [], set()
        for r in records:
            key = r.get('resume_id') or r.get('link') or r.get('candidate_name_web')
            if key and key not in seen:
                seen.add(key)
                uniq.append(r)
                if limit is not None and len(uniq) >= limit:
                    break

        # –æ—Ñ–ª–∞–π–Ω-—Å–Ω–∏–º–æ–∫ (MHTML –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É, —É–¥–∞–ª–∏–º –ø–æ–∑–∂–µ)
        ts = datetime.now(tz_target).strftime("%Y%m%d-%H%M%S")
        mhtml_path = OUTPUT_DIR / f"avito_paid_cvs_{ts}.mhtml"
        save_as_mhtml(page, mhtml_path)

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ API
        api_cache = process_resumes_parallel(uniq, tz_target, num_threads)
        
        # === –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ù–ï–î–û–°–¢–ê–Æ–©–ò–• –ß–ê–¢–û–í ===
        if NOT_FOUND_CHATS:
            print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(NOT_FOUND_CHATS)} –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤ –≤ –∫—ç—à
            recovered_count = add_missing_chats_to_cache(NOT_FOUND_CHATS)
            
            if recovered_count > 0:
                print(f"üéØ –£–°–ü–ï–®–ù–û –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–û {recovered_count} –∏–∑ {len(NOT_FOUND_CHATS)} –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤!")
                
                # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º CHATS_DATA –∏–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∫—ç—à–∞
                CHATS_DATA = load_chats_from_cache_and_api()
                print(f"üìä –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —á–∞—Ç–æ–≤: {len(CHATS_DATA)}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º NOT_FOUND_CHATS, —É–±–∏—Ä–∞—è –Ω–∞–π–¥–µ–Ω–Ω—ã–µ
                original_count = len(NOT_FOUND_CHATS)
                NOT_FOUND_CHATS = [chat_id for chat_id in NOT_FOUND_CHATS if chat_id not in CHATS_DATA]
                print(f"üìâ –û—Å—Ç–∞–ª–æ—Å—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤: {len(NOT_FOUND_CHATS)} (–∏–∑ {original_count})")
                
                # –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞
                success_rate = (recovered_count / original_count) * 100
                print(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {success_rate:.1f}%")
            else:
                print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —á–∞—Ç—ã –Ω–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å")
        else:
            print("‚úÖ –ù–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —á–∞—Ç–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        # === –ö–û–ù–ï–¶ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–Ø –ß–ê–¢–û–í ===

        # –∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
        df = pd.DataFrame.from_records(uniq)

        # –ª–æ–∫–∞–ª—å–Ω—ã–π now –¥–ª—è web-–¥–∞—Ç
        now_local_naive = datetime.now(tz_target).replace(tzinfo=None)

        # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç –∏–∑ –≤–µ–±–∞ ‚Üí *_web (naive, –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è TZ)
        for col in ("purchased_at_web", "updated_at_web"):
            if col in df.columns:
                df[col] = df[col].apply(lambda s: parse_ru_dt(s, now=now_local_naive))

        # –¥–æ–±–∞–≤–∏–º API-–ø–æ–ª—è (–±–µ—Ä—ë–º –∏–∑ api_cache)
        def _get(rid, key):
            return (api_cache.get(str(rid)) or {}).get(key, "")

        api_columns = [
            "fio_api",            # –Ω—É–∂–µ–Ω –¥–ª—è excluded_df/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –Ω–µ –≤—ã–≤–æ–¥–∏–º –≤ paid_cvs
            "phone_api", "email_api", "chat_id_api", "avito_id",
            "update_time_api",    # –Ω—É–∂–µ–Ω –¥–ª—è api_difference —Ä–∞—Å—á—ë—Ç–∞
            "updated_at_api",     # –¥–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ API –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å web
            "desired_title_api",
            # –£–¥–∞–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ API –ø–æ–ª—è: "location_api", "city_api", "region_api"
            "chat_status", "last_message_direction", "last_message_text",  # –Ω–æ–≤—ã–µ –ø–æ–ª—è v11
            "json_open", "json_paid",
        ]
        for c in api_columns:
            df[c] = df["resume_id"].map(lambda x: _get(x, c))

        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –°–¢–û–ü-–õ–ò–°–¢ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        stop_df, stoplist_file_stats = build_stoplist_from_output()
        stop_count = len(stop_df)
        excluded_df = pd.DataFrame(columns=[
            "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–ò—Å—Ç–æ—á–Ω–∏–∫", "respond_status"
        ])

        if stop_count > 0 and "phone_api" in df.columns:
            df["_phone_clean"] = _clean_phone_series(df["phone_api"]).fillna("")
            stop_df["_phone_clean"] = _clean_phone_series(stop_df[_DEF_COLS["phone"]]).fillna("")

            merged = df.merge(
                stop_df[["_phone_clean", _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]],
                on="_phone_clean", how="left"
            )

            mask_ex = merged[_DEF_COLS["comment"]].notna() | merged[_DEF_COLS["fio"]].notna()

            if mask_ex.any():
                merged["respond_status"] = merged.apply(
                    lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
                    axis=1
                )
                excluded_df = merged.loc[mask_ex, [
                    "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
                    _DEF_COLS["comment"], _DEF_COLS["fio"], "–§–∞–π–ª", "–õ–∏—Å—Ç", "respond_status"
                ]].rename(columns={
                    _DEF_COLS["comment"]: "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞",
                    _DEF_COLS["fio"]: "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞",
                })

            df = merged.loc[~mask_ex, df.columns].copy()
            df = df.drop(columns=["_phone_clean"], errors="ignore")
        else:
            df = df.copy()

        # –õ–∏–Ω–∫ –∏–∑ API (fallback ‚Äî web)
        def _build_precise_link(row) -> str:
            try:
                js = json.loads(row.get("json_open") or "{}")
                url_val = js.get("url") or js.get("uri") or (js.get("links") or {}).get("self") or js.get("link") or ""
                if url_val:
                    u = str(url_val)
                    return u if u.startswith("http") else ("https://www.avito.ru" + u)
            except Exception:
                pass
            w = str(row.get("link") or "")
            if w:
                return w if w.startswith("http") else ("https://www.avito.ru" + w)
            return ""

        df["link"] = df.apply(_build_precise_link, axis=1)

        # –ù–û–í–û–ï: ¬´–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç¬ª –∏–∑ chat_id_api
        df["–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç"] = df["chat_id_api"].apply(
            lambda x: f"https://www.avito.ru/profile/messenger/channel/{str(x).strip()}"
            if isinstance(x, str) and str(x).strip() else (
                f"https://www.avito.ru/profile/messenger/channel/{x}" if (x is not None and str(x).strip()) else ""
            )
        )

        # api_difference: –¥–Ω–∏ (updated_at_web - update_time_api)
        def _days_diff(a, b):
            try:
                if pd.isna(a) or pd.isna(b):
                    return pd.NA
                return int((pd.Timestamp(a) - pd.Timestamp(b)).days)
            except Exception:
                return pd.NA

        df["api_difference"] = df.apply(lambda r: _days_diff(r.get("updated_at_web"), r.get("update_time_api")), axis=1)

        # respond_status
        df["respond_status"] = df.apply(
            lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
            axis=1
        )

        # –∑–∞–∫—Ä—ã—Ç—ã–µ (json_paid –ø—É—Å—Ç–æ) ‚Üí –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–∏—Å—Ç
        def _is_json_paid_empty(v) -> bool:
            if pd.isna(v):
                return True
            s = str(v).strip()
            if not s:
                return True
            try:
                js = json.loads(s)
                if js in ({}, [], None):
                    return True
            except Exception:
                if s.lower() in ("{}", "[]", "null"):
                    return True
            return False

        if "json_paid" in df.columns:
            closed_mask = df["json_paid"].apply(_is_json_paid_empty)
        else:
            closed_mask = pd.Series(False, index=df.index)

        closed_df = df.loc[closed_mask].copy()
        if not closed_df.empty:
            closed_df["respond_status"] = closed_df.apply(
                lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
                axis=1
            )

        # –∏–∑ —Ä–∞–±–æ—á–∏—Ö df –∏—Å–∫–ª—é—á–∞–µ–º –∑–∞–∫—Ä—ã—Ç—ã–µ
        df = df.loc[~closed_mask].copy()

        # NO_ANSWER –ª–∏—Å—Ç (–Ω–µ —É–¥–∞–ª—è–µ–º –∏–∑ df)
        no_answer_mask = df.apply(lambda r: (not r.get("avito_id")) and bool(r.get("chat_id_api")), axis=1)
        no_answer_df = df.loc[no_answer_mask].copy()
        if not no_answer_df.empty:
            no_answer_df["respond_status"] = "NO_ANSWER"

        # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (–Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ, max —Ä–∞–∑–Ω–∏—Ü–∞ ‚Üí min)
        def _sort_df_for_output(dframe: pd.DataFrame) -> pd.DataFrame:
            sort_by = []
            if "updated_at_web" in dframe.columns:
                sort_by.append("updated_at_web")
            if "api_difference" in dframe.columns:
                sort_by.append("api_difference")
            if sort_by:
                ascending_flags = [False] * len(sort_by)
                try:
                    return dframe.sort_values(by=sort_by, ascending=ascending_flags, na_position="last")
                except Exception:
                    return dframe
            return dframe

        # –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–∏—Å—Ç–∞ "–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤" —Å —É—á–µ—Ç–æ–º —Å—Ç–∞—Ç—É—Å–æ–≤ —á–∞—Ç–æ–≤
        def _sort_df_for_calls(dframe: pd.DataFrame) -> pd.DataFrame:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            def get_priority(row):
                job_status = str(row.get("job_search_status_web", "")).lower()
                ready_start = str(row.get("ready_to_start_web", "")).lower()
                chat_status = str(row.get("chat_status", ""))
                
                # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω
                if chat_status == ChatStatus.NOT_INTERESTED.value:
                    return 9
                
                # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –≥–æ—Ç–æ–≤ –∑–∞–≤—Ç—Ä–∞/—Å—Ä–∞–∑—É + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if job_status and ready_start and chat_status == ChatStatus.READ_REPLIED.value:
                    return 1
                
                # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –≥–æ—Ç–æ–≤ –∑–∞–≤—Ç—Ä–∞/—Å—Ä–∞–∑—É
                if job_status and ready_start:
                    return 2
                
                # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if job_status and chat_status == ChatStatus.READ_REPLIED.value:
                    return 3
                
                # –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç —Ä–∞–±–æ—Ç—É
                if job_status:
                    return 4
                
                # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –≥–æ—Ç–æ–≤ –Ω–∞—á–∞—Ç—å –±—ã—Å—Ç—Ä–æ + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if ready_start and chat_status == ChatStatus.READ_REPLIED.value:
                    return 5
                
                # –ù–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: —Ç–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤ –Ω–∞—á–∞—Ç—å –±—ã—Å—Ç—Ä–æ
                if ready_start:
                    return 6
                
                # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ, –Ω–æ –±–µ–∑ –¥—Ä—É–≥–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
                if chat_status == ChatStatus.READ_REPLIED.value:
                    return 7
                
                # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π: —á–∏—Ç–∞–µ—Ç, –Ω–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
                if chat_status == ChatStatus.READ_NO_REPLY.value:
                    return 8
                
                # –û–±—ã—á–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤
                return 10
            
            dframe = dframe.copy()
            dframe["_priority"] = dframe.apply(get_priority, axis=1)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (1-10) ‚Üí –Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ ‚Üí –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
            sort_by = ["_priority"]
            ascending_flags = [True]  # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é (1 = –≤—ã—Å—à–∏–π)
            
            if "updated_at_web" in dframe.columns:
                sort_by.append("updated_at_web")
                ascending_flags.append(False)
            if "api_difference" in dframe.columns:
                sort_by.append("api_difference")
                ascending_flags.append(False)
            
            try:
                result = dframe.sort_values(by=sort_by, ascending=ascending_flags, na_position="last")
                # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
                result = result.drop(columns=["_priority"])
                return result
            except Exception:
                return dframe

        # –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (purchased_at_web ‚Äî –ü–ï–†–í–ê–Ø)
        desired_order = [
            "purchased_at_web",
            "updated_at_web", "updated_at_api", "candidate_name_web", "job_search_status_web", "ready_to_start_web",
            "chat_status", "last_message_direction", "last_message_text",
            "phone_api", "email_api", "desired_title_api", "city_web",
            # –£–¥–∞–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ API –ø–æ–ª—è: "city_api", "region_api", "location_api", "avito_id"
            "respond_status", "json_open", "json_paid", "link", "–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç", "chat_id_api", 
            "resume_id", "api_difference"
        ]

        # –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –ø–æ –º–∞–∫—Å. –¥–ª–∏–Ω–µ (header + –∑–Ω–∞—á–µ–Ω–∏—è)
        def _set_column_widths_autofit(ws, df_sheet):
            for i, col in enumerate(df_sheet.columns, start=1):
                col_letter = get_column_letter(i)
                header = str(col)
                values = df_sheet[col].astype(str).replace("nan", "").fillna("").tolist()
                max_len = len(header)
                for v in values:
                    l = len(v)
                    if l > max_len:
                        max_len = l
                width = max_len + 2
                if width < 4:
                    width = 4
                ws.column_dimensions[col_letter].width = width

        # ===== –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Excel –≤ –ù–û–í–û–ï –º–µ—Å—Ç–æ –∏ —É–¥–∞–ª–µ–Ω–∏–µ MHTML =====
        OUTPUT_SAVE_DIR = Path(r"C:\ManekiNeko\AVITO_API\output").resolve()
        OUTPUT_SAVE_DIR.mkdir(parents=True, exist_ok=True)

        now_dt = datetime.now(tz_target)
        date_part = now_dt.strftime("%d%m%Y")     # –î–î–ú–ú–ì–ì–ì–ì
        time_part = now_dt.strftime("%M_%S")      # –ú–ú_–°–°
        excel_name = f"{date_part}_–í—ã–≥—Ä—É–∑–∫–∞_–ê–ú–û_{time_part}.xlsx"
        excel_path = OUTPUT_SAVE_DIR / excel_name

        with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
            # PAID_CVS
            df_out = _sort_df_for_output(df)
            cols_full = [c for c in desired_order if c in df_out.columns]
            df_out[cols_full].to_excel(writer, index=False, sheet_name="paid_cvs")
            ws = writer.sheets["paid_cvs"]
            _set_column_widths_autofit(ws, df_out[cols_full])

            # NO_ANSWER
            if not no_answer_df.empty:
                noans_out = _sort_df_for_output(no_answer_df)
                cols_noans = [c for c in desired_order if c in noans_out.columns]
                noans_out[cols_noans].to_excel(writer, index=False, sheet_name="NO_ANSWER")
                ws_no = writer.sheets["NO_ANSWER"]
                _set_column_widths_autofit(ws_no, noans_out[cols_noans])

            # —Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ
            if not closed_df.empty:
                closed_out = _sort_df_for_output(closed_df)
                cols_closed = [c for c in desired_order if c in closed_out.columns]
                closed_out[cols_closed].to_excel(writer, index=False, sheet_name="—Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ")
                ws_closed = writer.sheets["—Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ"]
                _set_column_widths_autofit(ws_closed, closed_out[cols_closed])

            # –î–ª—è_–∑–≤–æ–Ω–∫–æ–≤ (–±–µ–∑ json_open/json_paid) —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            df_calls = df.copy()
            df_calls = _sort_df_for_calls(df_calls)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É
            cols_calls = [c for c in desired_order if c in df_calls.columns and c not in ("json_open", "json_paid")]
            df_calls[cols_calls].to_excel(writer, index=False, sheet_name="–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤")
            ws_calls = writer.sheets["–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤"]
            _set_column_widths_autofit(ws_calls, df_calls[cols_calls])

            # –Ω–∞_—Å–µ–≥–æ–¥–Ω—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞, –±–µ–∑ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞, –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)
            today_df = create_today_sheet(df, stop_df)
            if not today_df.empty:
                today_df = _sort_df_for_output(today_df)
                cols_today = [c for c in desired_order if c in today_df.columns and c not in ("json_open", "json_paid")]
                today_df[cols_today].to_excel(writer, index=False, sheet_name="–Ω–∞_—Å–µ–≥–æ–¥–Ω—è")
                ws_today = writer.sheets["–Ω–∞_—Å–µ–≥–æ–¥–Ω—è"]
                _set_column_widths_autofit(ws_today, today_df[cols_today])
                print(f"üìÖ –õ–∏—Å—Ç '–Ω–∞_—Å–µ–≥–æ–¥–Ω—è': {len(today_df)} –∑–∞–ø–∏—Å–µ–π (24 —á–∞—Å–∞, –±–µ–∑ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞, –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)")

            # –ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏ (–≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã —Å chat_status = "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è" + —Å—Å—ã–ª–∫–∏ –Ω–∞ —á–∞—Ç—ã)
            not_contacted_df = create_not_contacted_sheet(df)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å df –≤–∫–ª—é—á–∞—è —Å—Ç–æ–ø-–ª–∏—Å—Ç
            if not not_contacted_df.empty:
                not_contacted_df = _sort_df_for_output(not_contacted_df)
                cols_not_contacted = [c for c in desired_order + ["chat_url"] if c in not_contacted_df.columns and c not in ("json_open", "json_paid")]
                not_contacted_df[cols_not_contacted].to_excel(writer, index=False, sheet_name="–ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏")
                ws_not_contacted = writer.sheets["–ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏"]
                _set_column_widths_autofit(ws_not_contacted, not_contacted_df[cols_not_contacted])
                print(f"üí¨ –õ–∏—Å—Ç '–ö–æ–º—É_–Ω–µ_–ø–∏—Å–∞–ª–∏': {len(not_contacted_df)} –∑–∞–ø–∏—Å–µ–π (–≤–∫–ª—é—á–∞—è —Å—Ç–æ–ø-–ª–∏—Å—Ç)")

            # –ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ –Ω–æ–º–µ—Ä—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞ —á–∞—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ API)
            if NOT_FOUND_CHATS:
                not_found_df = create_not_found_chats_sheet(df)
                if not not_found_df.empty:
                    not_found_df = _sort_df_for_output(not_found_df)
                    cols_not_found = [c for c in desired_order + ["chat_url", "source"] if c in not_found_df.columns and c not in ("json_open", "json_paid")]
                    not_found_df[cols_not_found].to_excel(writer, index=False, sheet_name="–ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´")
                    ws_not_found = writer.sheets["–ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´"]
                    _set_column_widths_autofit(ws_not_found, not_found_df[cols_not_found])
                    print(f"‚ùå –õ–∏—Å—Ç '–ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´': {len(not_found_df)} –∑–∞–ø–∏—Å–µ–π (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ –Ω–æ–º–µ—Ä—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞)")
                else:
                    print("‚ö†Ô∏è –ù–ï_–ù–ê–ô–î–ï–ù–ù–´–ï_–ß–ê–¢–´ –ø—É—Å—Ç –ø–æ—Å–ª–µ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏")
            else:
                print("‚ÑπÔ∏è NOT_FOUND_CHATS –ø—É—Å—Ç - –Ω–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤")

            # –ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É
            if not excluded_df.empty:
                ex_cols_order = [c for c in [
                    "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
                    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–∞–π–ª", "–õ–∏—Å—Ç", "respond_status"
                ] if c in excluded_df.columns]
                excluded_df[ex_cols_order].to_excel(writer, index=False, sheet_name="–ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É")
                ws_ex = writer.sheets["–ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É"]
                _set_column_widths_autofit(ws_ex, excluded_df[ex_cols_order])

            # summary (–æ—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –µ—Å—Ç—å ‚Äî snapshot —Ö—Ä–∞–Ω–∏—Ç –∏–º—è —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ MHTML)
            not_found_count = len(create_not_found_chats_sheet(df)) if NOT_FOUND_CHATS else 0
            pd.DataFrame({
                "metric": [
                    "count_unique", "count_scroll_estimate", "snapshot", "page", "tz_name",
                    "stoplist_dir", "stoplist_size", "excluded_by_stoplist", "not_contacted_count", "not_found_chats_count",
                ],
                "value": [
                    len(df), total_cards_est, str(mhtml_path.name), TARGET_URL, tz_name,
                    str(STOPLIST_DIR), int(stop_count), int(len(excluded_df)), int(len(create_not_contacted_sheet(df))), not_found_count,
                ],
            }).to_excel(writer, index=False, sheet_name="summary")

        # –£–¥–∞–ª—è–µ–º MHTML –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–ø–∏—Å–∏ Excel
        try:
            mhtml_path.unlink()
            print(f"MHTML —É–¥–∞–ª—ë–Ω: {mhtml_path}")
        except FileNotFoundError:
            pass
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å MHTML ({mhtml_path}): {e}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É
        if stoplist_file_stats:
            print(f"\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞:")
            print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stop_count} –∑–∞–ø–∏—Å–µ–π")
            print(f"   –ò—Å–∫–ª—é—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(excluded_df)}")
            print(f"   –§–∞–π–ª—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏:")
            for filename, count in stoplist_file_stats.items():
                print(f"     ‚Ä¢ {filename}: {count} –∑–∞–ø–∏—Å–µ–π")
        else:
            print(f"\nüìã –°—Ç–æ–ø–ª–∏—Å—Ç –ø—É—Å—Ç (—Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ {STOPLIST_DIR})")

        print(f"\nüìä Excel: {excel_path}")

        context.close()

if __name__ == "__main__":
    main()
