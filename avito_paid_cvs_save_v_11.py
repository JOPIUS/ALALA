# avito_paid_cvs_save_v_11.py
# -*- coding: utf-8 -*-
"""
Avito: –ö—É–ø–ª–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ ‚Üí XLSX —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ç–∞—Ç—É—Å–æ–≤ —á–∞—Ç–æ–≤ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π.

v11 = v10 + –¢–ò–ü–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –°–¢–ê–¢–£–°–´ –ß–ê–¢–û–í –ò –°–û–û–ë–©–ï–ù–ò–ô
  ‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞ –æ–±—â–µ–Ω–∏—è —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º: "–ü—Ä–æ—á–∏—Ç–∞–ª/–Ω–µ –æ—Ç–≤–µ—Ç–∏–ª", "–ü—Ä–æ—á–∏—Ç–∞–ª/–û—Ç–≤–µ—Ç–∏–ª", "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è", "–ù–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ"
  ‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ —á–∞—Ç–æ–≤ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ messenger API
  ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏—è–º
  ‚Ä¢ –ù–æ–≤—ã–µ –ø–æ–ª—è: chat_status, last_message_direction, last_message_text
  ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ —á–∞—Ç–∞—Ö

–ü—Ä–µ–¥—ã–¥—É—â–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (v10):
  ‚Ä¢ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç—É—Å–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ ("–ê–∫—Ç–∏–≤–Ω–æ –∏—â—É —Ä–∞–±–æ—Ç—É", "–ì–æ—Ç–æ–≤ –≤—ã–π—Ç–∏ –∑–∞–≤—Ç—Ä–∞")
  ‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ "–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤"
  ‚Ä¢ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ API (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 5-8 —Ä–∞–∑)
  ‚Ä¢ –õ–∏—Å—Ç "–Ω–∞_—Å–µ–≥–æ–¥–Ω—è" —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ–≥–∏–æ–Ω–∞–º

CLI:
  python avito_paid_cvs_save_v_11.py --limit 100 --tz Europe/Moscow --threads 8

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
  pip install playwright pandas openpyxl requests tzdata
  python -m playwright install chromium
"""
from __future__ import annotations

from pathlib import Path
from datetime import datetime, timedelta, timezone
from playwright.sync_api import sync_playwright, Error as PwError
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum
from typing import List, Dict, Optional, Tuple
import re, time, json, sys, os
import pandas as pd

# ========== –¢–ò–ü–ò–ó–ê–¶–ò–Ø –°–¢–ê–¢–£–°–û–í –ß–ê–¢–û–í ==========

class ChatStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã —á–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    READ_NO_REPLY = "–ü—Ä–æ—á–∏—Ç–∞–ª/–Ω–µ –æ—Ç–≤–µ—Ç–∏–ª"           # –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª, –Ω–æ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª
    READ_REPLIED = "–ü—Ä–æ—á–∏—Ç–∞–ª/–û—Ç–≤–µ—Ç–∏–ª"               # –ö–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª –∏ –æ—Ç–≤–µ—Ç–∏–ª
    NO_MESSAGES_SENT = "–ù–µ –≤—ã—Å—ã–ª–∞–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"      # –ú—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    NOT_INTERESTED = "–ù–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ"                 # –ö–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–ø–∏—Å–∞–ª, —á—Ç–æ –Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ
    NO_CHAT = "–ß–∞—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"                     # –ù–µ—Ç —á–∞—Ç–∞ —Å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º
    UNKNOWN = "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π"                      # –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å

class MessageDirection(Enum):
    """–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    IN = "in"               # –í—Ö–æ–¥—è—â–µ–µ (–æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞)
    OUT = "out"             # –ò—Å—Ö–æ–¥—è—â–µ–µ (–æ—Ç –Ω–∞—Å)

# ===== TZ helper =====
try:
    from zoneinfo import ZoneInfo  # Python 3.9+
except Exception:
    try:
        from backports.zoneinfo import ZoneInfo  # type: ignore
    except Exception:
        ZoneInfo = None  # type: ignore

DEFAULT_TZ_NAME = "Europe/Moscow"

# ===== –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï =====
CHATS_DATA: Dict[str, Dict] = {}  # –î–∞–Ω–Ω—ã–µ —á–∞—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞

def _get_tz(tz_name: str):
    tz_name = (tz_name or DEFAULT_TZ_NAME).strip()
    if ZoneInfo is not None:
        try:
            return ZoneInfo(tz_name)
        except Exception:
            pass
    if tz_name in ("Europe/Moscow", "MSK", "RU-MOW"):
        return timezone(timedelta(hours=3))
    return timezone.utc

# ===== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–µ–±-—á–∞—Å—Ç–∏ =====
HOME_URL   = "https://www.avito.ru/"
TARGET_URL = "https://www.avito.ru/profile/paid-cvs"

USER_DATA_DIR = Path("./avito_browser_profile").resolve()
OUTPUT_DIR    = Path("./saved_pages").resolve(); OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

NAV_TIMEOUT            = 60_000
MAX_TOTAL_SCROLL_SEC   = 420
QUIET_MS               = 2000
STABLE_GROWTH_ROUNDS   = 5
MAX_WHEEL_STEPS        = 480
WHEEL_DELAY_SEC        = 0.20
WAIT_RESP_TIMEOUT_MS   = 6000
NETWORK_IDLE_GRACE     = 2

# ========== –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è/HTTP –∫ Avito API ==========
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

API_BASE = "https://api.avito.ru"
TIMEOUT  = 30

APP_NAME = "Resume Sercher"
CLIENT_ID     = "Dm4ruLMEr9MFsV72dN95"
CLIENT_SECRET = "f73lNoAJLzuqwoGtVaMnByhQfSlwcyIN_m7wyOeT"
REDIRECT_URL  = "https://hireworkers.ru/"

SESSION = requests.Session()
retry_cfg = Retry(
    total=5, connect=5, read=5,
    backoff_factor=0.5,
    status_forcelist=[429, 500, 502, 503, 504],
    allowed_methods=frozenset(["GET", "POST"]),
    raise_on_status=False,
)
SESSION.mount("https://", HTTPAdapter(max_retries=retry_cfg, pool_connections=10, pool_maxsize=10))
SESSION.headers.update({"User-Agent": f"{APP_NAME} / avito_paid_cvs_save_v6_6", "Accept": "application/json"})

class Token:
    def __init__(self) -> None:
        self._token: str | None = None
        self._exp: float = 0.0
        self.force_refresh_on_start = True
    def _refresh(self) -> None:
        r = SESSION.post(
            f"{API_BASE}/token",
            data={"grant_type": "client_credentials", "client_id": CLIENT_ID, "client_secret": CLIENT_SECRET},
            timeout=TIMEOUT,
        )
        r.raise_for_status()
        js = r.json()
        self._token = js["access_token"]
        self._exp = time.time() + int(js.get("expires_in", 3600)) - 20
        print("üîë access_token –æ–±–Ω–æ–≤–ª—ë–Ω")
    def get(self) -> str:
        if self.force_refresh_on_start or self._token is None or time.time() >= self._exp:
            self._refresh()
            self.force_refresh_on_start = False
        return self._token  # type: ignore[return-value]
_tok = Token()

import threading

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è rate limiting
_rate_limit_lock = threading.Lock()
_last_request_time = 0.0

def _respect_rate_limit(resp: requests.Response) -> None:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π rate limiting —Å –∞–Ω–∞–ª–∏–∑–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤."""
    global _last_request_time
    
    try:
        with _rate_limit_lock:
            remain = int(resp.headers.get("X-RateLimit-Remaining", "5"))
            limit = int(resp.headers.get("X-RateLimit-Limit", "100"))
            reset_time = resp.headers.get("X-RateLimit-Reset")
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤
            if remain <= 1:
                sleep_time = 1.0
            elif remain <= 5:
                sleep_time = 0.3
            elif remain <= 10:
                sleep_time = 0.1
            else:
                sleep_time = 0.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            
            # –£—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            current_time = time.time()
            elapsed = current_time - _last_request_time
            if elapsed < sleep_time:
                time.sleep(sleep_time - elapsed)
            
            _last_request_time = time.time()
            
    except Exception:
        # Fallback: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        time.sleep(0.05)

def avito_get_json(path: str, *, params: dict | None = None, timeout: int | None = None) -> dict:
    to = timeout or TIMEOUT
    for attempt in (1, 2):
        try:
            resp = SESSION.get(API_BASE + path, headers={"Authorization": "Bearer " + _tok.get()}, params=params, timeout=to)
            if resp.status_code == 200:
                _respect_rate_limit(resp)
                return resp.json()
            if resp.status_code in (401, 403) and attempt == 1:
                print(f"‚ö†Ô∏è  {resp.status_code} –Ω–∞ {path}. –û–±–Ω–æ–≤–ª—è—é —Ç–æ–∫–µ–Ω‚Ä¶")
                _tok.force_refresh_on_start = True
                _tok.get()
                continue
            print(f"‚ö†Ô∏è  GET {path} ‚Üí HTTP {resp.status_code}: {resp.text[:200]}...")
            return {}
        except requests.RequestException as e:
            if attempt == 1:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –Ω–∞ {path}: {e}. –†–µ—Ñ—Ä–µ—à —Ç–æ–∫–µ–Ω–∞‚Ä¶")
                _tok.force_refresh_on_start = True
                _tok.get()
                continue
            print(f"‚õî  –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –Ω–∞ {path} (–ø–æ–≤—Ç–æ—Ä –Ω–µ –ø–æ–º–æ–≥): {e}")
            return {}
    return {}

def _ensure_my_user_id() -> int:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞—à user_id –∏–∑ /core/v1/accounts/self.
    –¢–æ–∫–µ–Ω –±–µ—Ä—ë–º —á–µ—Ä–µ–∑ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π _tok/SESSION.
    """
    try:
        resp = SESSION.get(
            API_BASE + "/core/v1/accounts/self",
            headers={"Authorization": "Bearer " + _tok.get()},
            timeout=TIMEOUT,
        )
        if resp.status_code != 200:
            raise RuntimeError(f"/accounts/self HTTP {resp.status_code}: {resp.text[:200]}")
        data = resp.json() or {}
        uid = data.get("id") or data.get("user_id")
        if not uid:
            raise RuntimeError(f"/accounts/self: –ø–æ–ª–µ id/user_id –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {data}")
        return int(uid)
    except Exception as e:
        print(f"‚õî  _ensure_my_user_id() error: {e}")
        return 0

# ========== –ê–ù–ê–õ–ò–ó –°–¢–ê–¢–£–°–û–í –ß–ê–¢–û–í –ò –°–û–û–ë–©–ï–ù–ò–ô ==========

def load_chats_from_api() -> Dict[str, Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {chat_id: chat_data} –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞.
    """
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API...")
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
        token = _tok.get()
        if not token:
            print("‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–æ–≤")
            return {}
            
        # –ü–æ–ª—É—á–∞–µ–º user_id
        user_id = _ensure_my_user_id()
        if not user_id:
            print("‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å user_id –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–æ–≤")
            return {}
        
        headers = {'Authorization': f'Bearer {token}'}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —á–∞—Ç—ã –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ —Å –æ–±—Ö–æ–¥–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è offset
        all_chats = []
        limit = 100
        max_offset = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π offset —Å–æ–≥–ª–∞—Å–Ω–æ Swagger
        
        def fetch_chats_batch(unread_only=None):
            """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–∫–µ—Ç —á–∞—Ç–æ–≤ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –ø—Ä–æ—á—Ç–µ–Ω–∏—é"""
            batch_chats = []
            offset = 0
            
            while offset <= max_offset:
                params = {'offset': offset, 'limit': limit}
                if unread_only is not None:
                    params['unread_only'] = unread_only
                    
                chats_url = f"{API_BASE}/messenger/v2/accounts/{user_id}/chats"
                
                try:
                    response = SESSION.get(chats_url, headers=headers, params=params, timeout=TIMEOUT)
                    
                    if response.status_code != 200:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–æ–≤ (offset {offset}, unread_only={unread_only}): {response.status_code}")
                        
                        # –ü—Ä–∏ –æ—à–∏–±–∫–µ 401/403 –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω
                        if response.status_code in [401, 403]:
                            print("üîë –ü—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω...")
                            _tok.force_refresh_on_start = True
                            new_token = _tok.get()
                            headers['Authorization'] = f'Bearer {new_token}'
                            
                            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º
                            response = SESSION.get(chats_url, headers=headers, params=params, timeout=TIMEOUT)
                            if response.status_code == 200:
                                print("‚úÖ –¢–æ–∫–µ–Ω –æ–±–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
                            else:
                                print(f"‚ùå –î–∞–∂–µ —Å –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º –æ—à–∏–±–∫–∞: {response.status_code}")
                                break
                        elif response.status_code == 400:
                            print("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç API –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞")
                            break
                        else:
                            break
                        
                    data = response.json()
                    chats = data.get('chats', [])
                    
                    if not chats:
                        print(f"‚úÖ –ë–æ–ª—å—à–µ —á–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è unread_only={unread_only}")
                        break
                        
                    batch_chats.extend(chats)
                    filter_msg = f" (unread_only={unread_only})" if unread_only is not None else ""
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —á–∞—Ç–æ–≤: +{len(chats)}, –≤—Å–µ–≥–æ –≤ –ø–∞–∫–µ—Ç–µ: {len(batch_chats)}{filter_msg}")
                    
                    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                    if len(chats) < limit:
                        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –Ω–µ–ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è unread_only={unread_only}")
                        break
                        
                    offset += limit
                    time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —á–∞—Ç–æ–≤: {e}")
                    break
                    
            return batch_chats
        
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —á–∞—Ç—ã (—á–∏—Ç–∞–Ω–Ω—ã–µ –∏ –Ω–µ—á–∏—Ç–∞–Ω–Ω—ã–µ)
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —á–∞—Ç—ã...")
        all_chats.extend(fetch_chats_batch())
        
        # –ó–∞—Ç–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ —á–∞—Ç—ã 
        # (–º–æ–≥—É—Ç –±—ã—Ç—å –¥—Ä—É–≥–∏–µ —á–∞—Ç—ã –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ offset=1000)
        print("üì® –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ —á–∞—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ...")
        unread_chats = fetch_chats_batch(unread_only=True)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Ç—ã (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
        existing_chat_ids = {chat.get("id") for chat in all_chats if chat.get("id")}
        unread_added = 0
        for chat in unread_chats:
            if chat.get("id") and chat.get("id") not in existing_chat_ids:
                all_chats.append(chat)
                existing_chat_ids.add(chat.get("id"))
                unread_added += 1
                
        if unread_added > 0:
            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {unread_added} –Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–∞—Ç—ã –ø–æ —Ç–∏–ø–∞–º (–µ—Å–ª–∏ API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
        print("üîÑ –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–∞—Ç—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤...")
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —á–∞—Ç–æ–≤, –µ—Å–ª–∏ API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä chatTypes
            chat_types = ["u2i", "i2u", "public"]  # user-to-item, item-to-user, public
            for chat_type in chat_types:
                type_chats_url = f"{API_BASE}/messenger/v2/accounts/{user_id}/chats"
                type_params = {'offset': 0, 'limit': 100, 'chat_types': chat_type}
                
                type_response = SESSION.get(type_chats_url, headers=headers, params=type_params, timeout=TIMEOUT)
                if type_response.status_code == 200:
                    type_data = type_response.json()
                    type_chats = type_data.get('chats', [])
                    type_added = 0
                    
                    for chat in type_chats:
                        if chat.get("id") and chat.get("id") not in existing_chat_ids:
                            all_chats.append(chat)
                            existing_chat_ids.add(chat.get("id"))
                            type_added += 1
                            
                    if type_added > 0:
                        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {type_added} —á–∞—Ç–æ–≤ —Ç–∏–ø–∞ {chat_type}")
                else:
                    print(f"‚ö†Ô∏è –¢–∏–ø —á–∞—Ç–æ–≤ {chat_type} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {type_response.status_code}")
                        
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —á–∞—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º: {e}")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ v1 API (–º–æ–∂–µ—Ç –¥–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        print("üîÑ –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —á–∞—Ç—ã —á–µ—Ä–µ–∑ v1 API...")
        try:
            v1_chats_url = f"{API_BASE}/messenger/v1/accounts/{user_id}/chats"
            v1_params = {'offset': 0, 'limit': 100}
            v1_response = SESSION.get(v1_chats_url, headers=headers, params=v1_params, timeout=TIMEOUT)
            
            if v1_response.status_code == 200:
                v1_data = v1_response.json()
                v1_chats = v1_data.get('chats', [])
                v1_count_before = len(all_chats)
                
                for chat in v1_chats:
                    if chat.get("id") and chat.get("id") not in existing_chat_ids:
                        all_chats.append(chat)
                        existing_chat_ids.add(chat.get("id"))
                        
                v1_added = len(all_chats) - v1_count_before
                if v1_added > 0:
                    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {v1_added} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ v1 API")
                else:
                    print("‚úÖ v1 API –Ω–µ –¥–∞–ª –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤")
            else:
                print(f"‚ö†Ô∏è v1 API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {v1_response.status_code}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ v1 API: {e}")
                
        print(f"‚úÖ –ò—Ç–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —á–∞—Ç–æ–≤: {len(all_chats)}")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–∫—Ä—ã—Ç–∏–∏
        if len(all_chats) >= 1100:
            print("üéØ –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ü–æ–ª—É—á–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Ç–æ–≤")
        elif len(all_chats) >= 1000:
            print("‚úÖ –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –û–±—Ö–æ–¥ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è offset —Å—Ä–∞–±–æ—Ç–∞–ª")
        else:
            print("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ –º–µ–Ω—å—à–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞—Ç–æ–≤")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        chat_dict = {}
        for chat in all_chats:
            chat_id = chat.get("id")
            if chat_id:
                chat_dict[chat_id] = chat
                
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chat_dict)} —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API")
        return chat_dict
        
    except Exception as e:
        print(f"‚õî –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API: {e}")
        return {}


def load_chats_from_json(json_file_path: str = "avito_export_20250920_015400.json") -> Dict[str, Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: {chat_id: chat_data} –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞.
    """
    if not os.path.exists(json_file_path):
        print(f"‚ö†Ô∏è  Chat JSON file not found: {json_file_path}")
        return {}
        
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        chats = data.get("chats", [])
        chat_dict = {}
        
        for chat in chats:
            chat_id = chat.get("id")
            if chat_id:
                chat_dict[chat_id] = chat
                
        print(f"‚úÖ Loaded {len(chat_dict)} chats from {json_file_path}")
        return chat_dict
        
    except Exception as e:
        print(f"‚õî Error loading chats from JSON: {e}")
        return {}


def analyze_chat_from_json(chat_data: Dict) -> Tuple[str, str, str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ —á–∞—Ç–∞ –∏–∑ JSON —ç–∫—Å–ø–æ—Ä—Ç–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (chat_status, last_message_direction, last_message_text)
    """
    if not chat_data:
        return ChatStatus.NO_CHAT.value, "", ""
        
    last_message = chat_data.get("last_message", {})
    if not last_message:
        return ChatStatus.NO_MESSAGES_SENT.value, "", ""
        
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    direction = last_message.get("direction", "").lower()
    message_text = ""
    content = last_message.get("content", {})
    if isinstance(content, dict):
        message_text = content.get("text", "")[:500]  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É
        
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    if direction == "in":
        last_message_direction = "–í—Ö–æ–¥—è—â–µ–µ"
    elif direction == "out":
        last_message_direction = "–ò—Å—Ö–æ–¥—è—â–µ–µ"
    else:
        last_message_direction = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—á—Ç–µ–Ω–∏—è
    read_timestamp = last_message.get("read")
    delivered_timestamp = last_message.get("delivered")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —á–∞—Ç–∞
    if direction == "in":
        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Ö–æ–¥—è—â–µ–µ - –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–∞–ø–∏—Å–∞–ª
        if read_timestamp:
            chat_status = ChatStatus.READ_NO_REPLY.value  # –ü—Ä–æ—á–∏—Ç–∞–ª–∏, –Ω–æ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∏
        else:
            chat_status = ChatStatus.READ_NO_REPLY.value  # –í—Ö–æ–¥—è—â–∏–µ –æ–±—ã—á–Ω–æ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–º–∏
    elif direction == "out":
        # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏—Å—Ö–æ–¥—è—â–µ–µ - –º—ã –Ω–∞–ø–∏—Å–∞–ª–∏
        if read_timestamp:
            chat_status = ChatStatus.READ_REPLIED.value  # –û—Ç–ø—Ä–∞–≤–∏–ª–∏ –∏ –∫–∞–Ω–¥–∏–¥–∞—Ç –ø—Ä–æ—á–∏—Ç–∞–ª
        else:
            chat_status = ChatStatus.NO_MESSAGES_SENT.value  # –û—Ç–ø—Ä–∞–≤–∏–ª–∏, –Ω–æ –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ
    else:
        chat_status = ChatStatus.UNKNOWN.value
        
    return chat_status, last_message_direction, message_text


def get_chat_messages(chat_id: str, limit: int = 100) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞ –ø–æ chat_id.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π.
    """
    if not chat_id:
        return []

    my_uid = _ensure_my_user_id()
    if not my_uid:
        return []

    try:
        url = f"{API_BASE}/messenger/v3/accounts/{my_uid}/chats/{chat_id}/messages/"
        params = {"limit": min(limit, 100), "offset": 0}
        r = SESSION.get(url, headers={"Authorization": "Bearer " + _tok.get()}, params=params, timeout=TIMEOUT)
        
        if r.status_code != 200:
            return []
            
        payload = r.json() or {}
        
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞
        messages = []
        if isinstance(payload.get("messages"), list):
            messages = payload["messages"]
        elif isinstance(payload.get("messages"), dict) and isinstance(payload["messages"].get("messages"), list):
            messages = payload["messages"]["messages"]
        elif isinstance(payload.get("result"), list):
            messages = payload["result"]
            
        return messages
        
    except Exception as e:
        print(f"‚ö†Ô∏è get_chat_messages error for {chat_id}: {e}")
        return []


def determine_chat_status(chat_id: str, my_user_id: int) -> tuple[ChatStatus, Optional[str], Optional[str]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å —á–∞—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        (chat_status, last_message_direction, last_message_text)
    """
    if not chat_id:
        return ChatStatus.NO_CHAT, None, None
    
    messages = get_chat_messages(chat_id, limit=50)
    if not messages:
        return ChatStatus.NO_CHAT, None, None
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–Ω–∞—á–∞–ª–∞)
    messages.sort(key=lambda m: m.get('created', 0), reverse=True)
    
    our_messages = []
    candidate_messages = []
    
    for msg in messages:
        direction = str(msg.get('direction', '')).lower()
        author_id = msg.get('author_id')
        
        try:
            author_id = int(author_id) if author_id else None
        except:
            author_id = None
        
        if direction == MessageDirection.OUT.value:
            our_messages.append(msg)
        elif direction == MessageDirection.IN.value:
            candidate_messages.append(msg)
        elif author_id == my_user_id:
            our_messages.append(msg)
        elif author_id and author_id != my_user_id:
            candidate_messages.append(msg)
    
    # –ï—Å–ª–∏ –º—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    if not our_messages:
        return ChatStatus.NO_MESSAGES_SENT, None, None
    
    # –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–ª
    if not candidate_messages:
        return ChatStatus.READ_NO_REPLY, MessageDirection.OUT.value, None
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    last_message = messages[0] if messages else None
    last_message_direction = None
    last_message_text = None
    
    if last_message:
        last_direction = str(last_message.get('direction', '')).lower()
        last_author_id = last_message.get('author_id')
        
        try:
            last_author_id = int(last_author_id) if last_author_id else None
        except:
            last_author_id = None
        
        if last_direction == MessageDirection.IN.value or (last_author_id and last_author_id != my_user_id):
            last_message_direction = MessageDirection.IN.value
        else:
            last_message_direction = MessageDirection.OUT.value
        
        last_message_text = last_message.get('content', {}).get('text', '') if last_message.get('content') else ''
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–∞—Ç—É—Å
    if candidate_messages:
        chat_status = ChatStatus.READ_REPLIED
    else:
        chat_status = ChatStatus.READ_NO_REPLY
    
    return chat_status, last_message_direction, last_message_text


# ‚Äî‚Äî‚Äî Avito Job API wrappers

def get_resume_open_json(resume_id: str) -> dict:
    """GET /job/v2/resumes/{id} ‚Äî –æ—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ (Resume 2.0)."""
    return avito_get_json(f"/job/v2/resumes/{resume_id}") or {}

def get_resume_paid_contacts_json(resume_id: str) -> dict:
    """GET /job/v1/resumes/{id}/contacts ‚Äî –∫—É–ø–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã (ResumeContacts)."""
    js = avito_get_json(f"/job/v1/resumes/{resume_id}/contacts", timeout=TIMEOUT + 10)
    if js:
        return js
    return avito_get_json(f"/job/v1/resumes/{resume_id}/contacts/", timeout=TIMEOUT + 10) or {}

# ========== –°–∫—Ä–æ–ª–ª/—ç–∫—Å—Ç—Ä–∞–∫—Ç ==========
ROBUST_SCROLL_LIMIT_JS = rf"""
  async (need) => {{
    const deadline = Date.now() + {MAX_TOTAL_SCROLL_SEC} * 1000;
    const quietMs  = {QUIET_MS};
    document.documentElement.style.scrollBehavior = 'auto';
    const sleep = (ms) => new Promise(r => setTimeout(r, ms));
    const norm = s => (s||'').replace(/\s+/g,' ').trim();
    const listSelector = '[data-marker="cv-snippet"]';

    let lastMutation = Date.now();
    const mo = new MutationObserver(() => {{ lastMutation = Date.now(); }});
    mo.observe(document.body, {{childList:true, subtree:true}});

    async function clickMore() {{
      const reMore = /(–ø–æ–∫–∞–∑–∞—Ç[—å—ä]\s*–µ—â[–µ—ë]|–ø–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ|–µ—â—ë|–∑–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë)/i;
      const btns = Array.from(document.querySelectorAll('button,a')).filter(b => reMore.test(norm(b.textContent)));
      for (const b of btns) {{ if (!b.disabled && !b.getAttribute('aria-disabled')) {{ b.click(); await sleep(350); }} }}
    }}

    let lastCount = 0, stableRounds = 0;
    const cards = () => Array.from(document.querySelectorAll(listSelector));

    while (Date.now() < deadline) {{
      window.scrollTo(0, document.body.scrollHeight);
      await sleep(450);
      await clickMore();

      window.scrollBy(0, -200); await sleep(150);
      window.scrollTo(0, document.body.scrollHeight); await sleep(450);

      const curCount = cards().length;
      const quiet = (Date.now() - lastMutation) > quietMs;
      if (curCount <= lastCount && quiet) stableRounds++; else {{ stableRounds=0; lastCount=curCount; }}
      if (need && curCount >= need) break;
      if (stableRounds >= {STABLE_GROWTH_ROUNDS}) break;
    }}

    let before = cards().length;
    for (let i = 0; i < cards().length && Date.now() < deadline; i++) {{
      try {{ cards()[i].scrollIntoView({{block:'center'}}); }} catch(e) {{}}
      await sleep(140);
      await clickMore();
      window.scrollBy(0, 120); await sleep(80); window.scrollBy(0, -120);
      await sleep(120);
      const cur = cards().length;
      if (need && cur >= need) break;
      if (cur > before) {{ before = cur; i = Math.max(0, i-3); }}
    }}

    for (let k=0;k<10;k++) {{
      window.scrollTo(0, document.body.scrollHeight); await sleep(400); await clickMore();
      if (need && cards().length >= need) break;
    }}

    mo.disconnect();
    const total = cards().length;
    return need ? Math.min(total, need) : total;
  }}
"""

COUNT_CARDS_JS = '() => document.querySelectorAll(\'[data-marker="cv-snippet"]\').length'

EXTRACT_JS = r"""
  () => {
    const norm = s => (s||'').replace(/\s+/g,' ').trim();
    const q = (root, sel) => root.querySelector(sel);

    const getDateText = (card, preferSel, labelRx) => {
      for (const sel of preferSel) {
        const el = sel ? card.querySelector(sel) : null;
        const txt = norm(el?.textContent);
        if (txt) return txt;
      }
      const full = norm(card.textContent || '');
      const m = full.match(labelRx);
      return m ? norm(m[0]) : '';
    };

    const out = [], seen = new Set();
    const cards = Array.from(document.querySelectorAll('[data-marker="cv-snippet"]'));

    for (const card of cards) {
      const linkEl = card.querySelector('a[href]');
      const link = linkEl ? new URL(linkEl.getAttribute('href'), location.origin).href : '';
      const rid  = (link.match(/\/(\d+)(?:\?|$)/)||[])[1] || '';

      const purchasedRaw = getDateText(
        card,
        ['[data-marker="cv-snippet/date/item-bought"]', '[data-marker*="date"]'],
        /(–ö—É–ø–ª–µ–Ω–æ\s+(?:—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|\d{1,2}\s+[–ê-–Ø–∞-—è–Å—ë\.]+(?:\s+\d{4})?\s+–≤\s+\d{1,2}:\d{2}))/i
      );
      const updatedRaw = getDateText(
        card,
        ['[data-marker="cv-snippet/date/item-changed"]', '[data-marker*="date"]'],
        /((?:–û–±–Ω–æ–≤–ª–µ–Ω–æ|–£–¥–∞–ª–µ–Ω–æ)\s+(?:—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞|\d{1,2}\s+[–ê-–Ø–∞-—è–Å—ë\.]+(?:\s+\d{4})?\s+–≤\s+\d{1,2}:\d{2}))/i
      );

      // –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —Ä–∞–±–æ—Ç–µ
      const fullText = norm(card.textContent || '');
      
      // –£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ä–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç—É—Å–æ–≤
      const jobSearchStatus = fullText.match(/(–∞–∫—Ç–∏–≤–Ω–æ\s+–∏—â[–∞—É–µ—ã—É]|–∏—â[–∞—É–µ—ã—É]\s+—Ä–∞–±–æ—Ç—É|–∞–∫—Ç–∏–≤–µ–Ω|–≥–æ—Ç–æ–≤\s+–∫\s+—Ä–∞–±–æ—Ç–µ|—Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é\s+–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)/i)?.[0] || '';
      
      // –ò—â–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –±—ã—Å—Ç—Ä–æ–º—É –Ω–∞—á–∞–ª—É —Ä–∞–±–æ—Ç—ã  
      const readyToStart = fullText.match(/(–≥–æ—Ç–æ–≤\s+(?:–≤—ã–π—Ç–∏|–ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å|–Ω–∞—á–∞—Ç—å)?\s*(?:–∑–∞–≤—Ç—Ä–∞|—Å–µ–≥–æ–¥–Ω—è|–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ|—Å—Ä–∞–∑—É)|–º–æ–≥—É\s+–ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å|–Ω–∞—á–Ω[—É—ã]|–≥–æ—Ç–æ–≤\s+(?:–∑–∞–≤—Ç—Ä–∞|—Å–µ–≥–æ–¥–Ω—è|—Å—Ä–∞–∑—É))/i)?.[0] || '';

      const rec = {
        candidate_name_web: norm(q(card, '[data-marker="cv-snippet/title"]')?.textContent),
        city_web:           norm(q(card, '[data-marker="cv-snippet/address"]')?.textContent),
        link: link, resume_id: rid,
        purchased_at_web: purchasedRaw,
        updated_at_web:   updatedRaw,
        photo_url_web:     q(card, 'img[src]')?.src || '',
        job_search_status_web: jobSearchStatus,
        ready_to_start_web: readyToStart
      };

      const key = rec.resume_id || rec.link || rec.candidate_name_web;
      if (key && !seen.has(key)) { seen.add(key); out.push(rec); }
    }
    return out;
  }
"""

# ========== –†—É—Å—Å–∫–∏–µ –¥–∞—Ç—ã ==========
RU_MONTHS = {
    "—è–Ω–≤–∞—Ä—è":1,"—Ñ–µ–≤—Ä–∞–ª—è":2,"–º–∞—Ä—Ç–∞":3,"–∞–ø—Ä–µ–ª—è":4,"–º–∞—è":5,"–∏—é–Ω—è":6,
    "–∏—é–ª—è":7,"–∞–≤–≥—É—Å—Ç–∞":8,"—Å–µ–Ω—Ç—è–±—Ä—è":9,"–æ–∫—Ç—è–±—Ä—è":10,"–Ω–æ—è–±—Ä—è":11,"–¥–µ–∫–∞–±—Ä—è":12,
    "—è–Ω–≤":1,"—Ñ–µ–≤":2,"–º–∞—Ä":3,"–∞–ø—Ä":4,"–º–∞–π":5,"–º–∞—è":5,"–∏—é–Ω":6,"–∏—é–ª":7,
    "–∞–≤–≥":8,"—Å–µ–Ω":9,"—Å–µ–Ω—Ç":9,"–æ–∫—Ç":10,"–Ω–æ—è":11,"–¥–µ–∫":12,
    "—è–Ω–≤.":1,"—Ñ–µ–≤.":2,"–º–∞—Ä.":3,"–∞–ø—Ä.":4,"–∏—é–Ω.":6,"–∏—é–ª.":7,"–∞–≤–≥.":8,"—Å–µ–Ω.":9,"—Å–µ–Ω—Ç.":9,"–æ–∫—Ç.":10,"–Ω–æ—è.":11,"–¥–µ–∫.":12,
}

def _normalize_ru_dt_string(s: str) -> str:
    s = (s or "").lower().replace("\u00a0"," ").replace("—ë","–µ")
    s = re.sub(r"[¬∑‚Ä¢]\s*$","", s).strip()
    s = re.sub(r"^(–∫—É–ø–ª–µ–Ω[–æ–∞]?|–æ–±–Ω–æ–≤–ª–µ–Ω[–æ–∞]?|—É–¥–∞–ª–µ–Ω[–æ–∞]?|—Å–æ–∑–¥–∞–Ω[–æ–∞]?|–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω[–æ–∞]?|—Ä–∞–∑–º–µ—â–µ–Ω[–æ–∞]?)\s+","", s)
    s = re.sub(r"\s+\d{4}\s*(?:–≥\.?|–≥–æ–¥–∞)$","", s)
    return s.strip()

def parse_ru_dt(s: str, now: datetime | None = None) -> pd.Timestamp:
    if not s:
        return pd.NaT
    s_norm = _normalize_ru_dt_string(s)
    now = now or datetime.now()

    m = re.search(r"(—Å–µ–≥–æ–¥–Ω—è|–≤—á–µ—Ä–∞)\s*–≤\s*(\d{1,2})\s*:\s*(\d{2})", s_norm)
    if m:
        tag, hh, mm = m.groups()
        dt = now.replace(hour=int(hh), minute=int(mm), second=0, microsecond=0)
        if tag == "–≤—á–µ—Ä–∞":
            dt -= timedelta(days=1)
        return pd.Timestamp(dt.replace(tzinfo=None))

    text = s_norm.lower().replace("\u00a0", " ")
    m = re.search(r"(\d{1,2})\s+([–∞-—è\.]+)(?:\s+(\d{4}))?\s+–≤\s+(\d{1,2}):(\d{2})", text)
    if m:
        d, mon_word, year_str, hh, mm = m.groups()
        mon = RU_MONTHS.get(mon_word, RU_MONTHS.get(mon_word.rstrip(".")))
        if not mon:
            return pd.NaT
        year = int(year_str) if year_str else (now.year - (1 if mon > now.month else 0))
        try:
            base = datetime(year, int(mon), int(d), int(hh), int(mm))
            return pd.Timestamp(base)
        except Exception:
            return pd.NaT

    return pd.NaT

# ========== STOPLIST (–∂—ë—Å—Ç–∫–æ: C:\\ManekiNeko\\AVITO_API\\output) ==========
STOPLIST_DIR = Path(r"C:\\ManekiNeko\\AVITO_API\\output").resolve()

_FIO_PATTERNS = [
    r"\b—Ñ\.?–∏\.?–æ\.?\b", r"\b—Ñ–∏–æ\b", r"\b–∏–º—è\b", r"\b—Ñ–∞–º–∏–ª", r"–∫–∞–Ω–¥–∏–¥–∞—Ç", r"—Å–æ–∏—Å–∫–∞—Ç–µ–ª", r"applicant", r"name", r"full\s*name"
]
_PHONE_PATTERNS = [r"—Ç–µ–ª", r"phone", r"–Ω–æ–º–µ—Ä", r"mobile", r"mob"]
_COMMENT_PATTERNS = [r"–ø–æ–ª–Ω—ã–π\s*–∫–æ–º–º–µ–Ω—Ç", r"–ø–æ–ª–Ω—ã–π\s*–∫–æ–º–º–µ–Ω—Ç–∞—Ä", r"comment", r"–∫–æ–º–º–µ–Ω—Ç", r"–∑–∞–º–µ—á–∞–Ω–∏", r"–ø—Ä–∏–º–µ—á–∞–Ω"]

_DEF_COLS = {"phone": "–¢–µ–ª–µ—Ñ–æ–Ω", "fio": "–§–ò–û", "comment": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"}

def _clean_phone_series(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.replace(r"\D", "", regex=True)
    s = s.str.replace(r"^8(?=\d{10}$)", "7", regex=True)
    mask10 = s.str.match(r"^\d{10}$")
    s.loc[mask10] = "7" + s[mask10]
    return s

def _find_col(cols: list[str], patterns: list[str]) -> str | None:
    low = [c.lower().strip() for c in cols]
    for p in patterns:
        rx = re.compile(p, re.IGNORECASE)
        for i, name in enumerate(low):
            if rx.search(name):
                return cols[i]
    return None


def build_stoplist_from_output() -> tuple[pd.DataFrame, dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (stoplist_df, file_stats)
    –≥–¥–µ file_stats = {"filename": count_records, ...}
    """
    rows: list[pd.DataFrame] = []
    file_stats = {}
    if not STOPLIST_DIR.exists():
        return pd.DataFrame(columns=[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]), {}

    SHEET_NAME = "–°—Ç–æ–ø–ª–∏—Å—Ç_—Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"
    EXPECTED_PHONE = "—Ç–µ–ª–µ—Ñ–æ–Ω"
    EXPECTED_FIO = "—Ñ–∏–æ"
    EXPECTED_COMMENT_FULL = "–ø–æ–ª–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"

    for fp in STOPLIST_DIR.glob("*.xlsx"):
        if fp.name.startswith("~$"):
            continue
        try:
            xl = pd.ExcelFile(fp, engine="openpyxl")
            if SHEET_NAME not in xl.sheet_names:
                continue

            df = xl.parse(SHEET_NAME)
            if df.empty:
                continue

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            low2orig = {str(c).strip(): c for c in df.columns}
            lowmap = {k.lower(): v for k, v in low2orig.items()}

            phone_col   = lowmap.get(EXPECTED_PHONE)
            fio_col     = lowmap.get(EXPECTED_FIO)
            comment_col = lowmap.get(EXPECTED_COMMENT_FULL)

            # –ë–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ ‚Äî —ç—Ç–æ –Ω–µ —Å—Ç–æ–ø–ª–∏—Å—Ç
            if not phone_col:
                continue

            sub = pd.DataFrame()
            sub[_DEF_COLS["phone"]] = _clean_phone_series(df[phone_col])
            sub[_DEF_COLS["fio"]] = df[fio_col] if fio_col else ""
            # –í–Ω—É—Ç—Ä–∏ —Å–∏—Å—Ç–µ–º—ã ¬´–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π¬ª ‚Äî —ç—Ç–æ —Ç–æ, —á—Ç–æ –Ω–∞ –ª–∏—Å—Ç–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è ¬´–ü–æ–ª–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π¬ª
            sub[_DEF_COLS["comment"]] = df[comment_col] if comment_col else ""
            sub["–§–∞–π–ª"], sub["–õ–∏—Å—Ç"] = fp.name, SHEET_NAME

            # –æ—Ç–±—Ä–æ—Å–∏–º –ø—É—Å—Ç—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã
            sub = sub[sub[_DEF_COLS["phone"]].astype(str).str.len() > 0]
            if not sub.empty:
                file_stats[fp.name] = len(sub)
                rows.append(sub[[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]])
        except Exception:
            continue

    if not rows:
        return pd.DataFrame(columns=[_DEF_COLS["phone"], _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]), {}

    all_df = pd.concat(rows, ignore_index=True)
    all_df[_DEF_COLS["phone"]] = _clean_phone_series(all_df[_DEF_COLS["phone"]])

    # –î–µ–¥—É–ø –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É: –æ—Å—Ç–∞–≤–∏–º –∑–∞–ø–∏—Å—å —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –¥–ª–∏–Ω–æ–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
    try:
        all_df["_clen"] = all_df[_DEF_COLS["comment"]].astype(str).map(len)
        all_df = all_df.sort_values([_DEF_COLS["phone"], "_clen"], ascending=[True, False])
        all_df = all_df.drop_duplicates(subset=[_DEF_COLS["phone"]], keep="first")
        all_df = all_df.drop(columns=["_clen"])
    except Exception:
        all_df = all_df.drop_duplicates(subset=[_DEF_COLS["phone"]], keep="first")

    return all_df.reset_index(drop=True), file_stats

# ========== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –≤–µ–±-—Ñ—É–Ω–∫—Ü–∏–∏ ==========

def save_as_mhtml(page, out_path: Path):
    s = page.context.new_cdp_session(page)
    s.send("Page.enable")
    data = s.send("Page.captureSnapshot", {"format": "mhtml"})["data"]
    out_path.write_text(data, encoding="utf-8")
    return out_path

def goto_resilient(page, url, expect_pattern, attempts=3):
    for _ in range(attempts):
        try: page.goto(url, wait_until="commit", timeout=NAV_TIMEOUT)
        except PwError: pass
        try:
            page.wait_for_url(expect_pattern, wait_until="domcontentloaded", timeout=30_000)
            return True
        except PwError:
            try: page.goto(HOME_URL, wait_until="domcontentloaded", timeout=30_000)
            except PwError: pass
    return False

def robust_scroll(page, need_count: int | None = None) -> int:
    try:
        count1 = page.evaluate(ROBUST_SCROLL_LIMIT_JS, need_count)
    except Exception:
        count1 = 0

    last_h, still = 0, 0
    for _ in range(MAX_WHEEL_STEPS):
        try: page.mouse.wheel(0, 1600)
        except Exception: pass
        time.sleep(WHEEL_DELAY_SEC)
        try: h = page.evaluate("Math.max(document.body.scrollHeight, document.documentElement.scrollHeight)")
        except Exception: h = last_h
        if h <= last_h:
            still += 1
            if still >= 6: break
        else:
            still = 0; last_h = h
        if need_count is not None:
            try:
                cur = int(page.evaluate(COUNT_CARDS_JS))
                if cur >= int(need_count):
                    break
            except Exception:
                pass

    quiet = 0
    while quiet < NETWORK_IDLE_GRACE:
        try:
            page.wait_for_response(
                lambda r: ("avito.ru" in r.url) and r.status == 200 and
                          (getattr(r.request, "resource_type", None) in ("xhr","fetch")),
                timeout=WAIT_RESP_TIMEOUT_MS
            )
            quiet = 0
        except Exception:
            quiet += 1

    try:
        count2 = int(page.evaluate(COUNT_CARDS_JS))
    except Exception:
        count2 = count1
    return min(count2, need_count) if need_count else max(count1, count2)

# ========== ENRICH (API): –§–ò–û/–∫–æ–Ω—Ç–∞–∫—Ç—ã/is_purchased/update_time ==========

def _salary_to_text(sal):
    if sal is None:
        return ""
    if isinstance(sal, (int, float)):
        return str(int(sal))
    if isinstance(sal, dict):
        lo = sal.get("from")
        hi = sal.get("to")
        cur = sal.get("currency", "")
        rng = "" if (lo is None and hi is None) else f"{lo or ''}‚Äì{hi or ''}"
        return (rng + (f" {cur}" if cur else "")).strip()
    return str(sal)


def enrich_one(resume_id: str, tz_target) -> dict:
    open_js = get_resume_open_json(resume_id)
    paid_js = get_resume_paid_contacts_json(resume_id)

    phone = email = chat_id = ""
    fio = ""
    first_name = last_name = patronymic = ""

    if paid_js:
        fio = (paid_js.get("name") or "")[:256].strip()
        fn = paid_js.get("full_name") or {}
        first_name  = str(fn.get("first_name") or "")
        last_name   = str(fn.get("last_name") or "")
        patronymic  = str(fn.get("patronymic") or "")
        if not fio:
            fio = " ".join(x for x in (last_name, first_name, patronymic) if x).strip()
        for c in (paid_js.get("contacts") or []):
            t = str(c.get("type") or "").lower()
            v = str(c.get("value") or "")
            if   t == "phone":   phone = v
            elif t in ("e-mail", "email"):  email = v
            elif t == "chat_id": chat_id = v

    # <-- –ù–û–í–û–ï v11: –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞ —á–∞—Ç–∞ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ JSON —Ñ–∞–π–ª–∞
    chat_status = ChatStatus.NO_CHAT.value
    last_message_direction = None
    last_message_text = None
    
    if chat_id and CHATS_DATA:
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ API –≤—ã–∑–æ–≤–æ–≤
            chat_data = CHATS_DATA.get(chat_id)
            if chat_data:
                status, direction, text = analyze_chat_from_json(chat_data)
                chat_status = status
                last_message_direction = direction
                last_message_text = text[:200] if text else None  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                print(f"‚úÖ Chat {chat_id}: {status} | {direction}")
            else:
                print(f"‚ö†Ô∏è  Chat {chat_id} not found in loaded data")
        except Exception as e:
            print(f"‚ö†Ô∏è  chat status analysis failed for {chat_id}: {e}")

    is_purchased_api = bool(open_js.get("is_purchased")) if isinstance(open_js, dict) else False
    update_time_api_raw = str(open_js.get("update_time") or "") if isinstance(open_js, dict) else ""

    try:
        ut = pd.to_datetime(update_time_api_raw, errors="coerce", utc=True)
        if pd.isna(ut):
            update_time_api = pd.NaT
        else:
            local = ut.tz_convert(tz_target)
            update_time_api = local.tz_localize(None)
    except Exception:
        update_time_api = pd.NaT

    desired_title_api   = str(open_js.get("title") or "")
    salary_expected_api = _salary_to_text(open_js.get("salary"))
    
    return {
        "fio_api": fio,
        "first_name_api": first_name,
        "last_name_api": last_name,
        "patronymic_api": patronymic,
        "phone_api": phone,
        "email_api": email,
        "chat_id_api": chat_id,      # –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ
        "is_purchased_api": is_purchased_api,
        "update_time_api": update_time_api,
        "updated_at_api": update_time_api,  # –∫–æ–ø–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—è–¥–æ–º —Å updated_at_web
        "update_time_api_raw": update_time_api_raw,
        "desired_title_api": desired_title_api,
        "salary_expected_api": salary_expected_api,
        # –ù–æ–≤—ã–µ –ø–æ–ª—è v11 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Ç–æ–≤
        "chat_status": chat_status,
        "last_message_direction": last_message_direction,
        "last_message_text": last_message_text,
        "json_open": json.dumps(open_js, ensure_ascii=False),
        "json_paid": json.dumps(paid_js, ensure_ascii=False),
    }


# ========== –í–≤–æ–¥ –ª–∏–º–∏—Ç–∞/TZ ==========

def _parse_limit_arg(argv: list[str]) -> int | None:
    try:
        if "--limit" in argv:
            i = argv.index("--limit")
            return max(0, int(argv[i+1]))
        if "-n" in argv:
            i = argv.index("-n")
            return max(0, int(argv[i+1]))
    except Exception:
        pass
    return None

def _parse_tz_arg(argv: list[str]) -> str | None:
    try:
        if "--tz" in argv:
            i = argv.index("--tz")
            return argv[i+1]
        if "-t" in argv:
            i = argv.index("-t")
            return argv[i+1]
    except Exception:
        pass
    return None

def _parse_threads_arg(argv: list[str]) -> int:
    """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    try:
        if "--threads" in argv:
            i = argv.index("--threads")
            return max(1, min(20, int(argv[i+1])))  # –û—Ç 1 –¥–æ 20 –ø–æ—Ç–æ–∫–æ–≤
        if "-j" in argv:
            i = argv.index("-j")
            return max(1, min(20, int(argv[i+1])))
    except Exception:
        pass
    return 8  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 8 –ø–æ—Ç–æ–∫–æ–≤


def ask_limit_from_user() -> int | None:
    s = input("–°–∫–æ–ª—å–∫–æ —Ä–µ–∑—é–º–µ —Å–æ–±—Ä–∞—Ç—å? –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ 'all' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: all): ").strip().lower()
    if not s or s in ("all", "–≤—Å–µ"):
        return None
    try:
        n = int(s)
        return n if n > 0 else None
    except Exception:
        print("–ù–µ –ø–æ–Ω—è–ª –≤–≤–æ–¥. –ë—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω–æ '–≤—Å–µ'.")
        return None


def enrich_resume_batch(resume_ids: list[str], tz_target, max_workers: int = 8) -> dict[str, dict]:
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ —á–µ—Ä–µ–∑ ThreadPoolExecutor.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {resume_id: enriched_data}
    """
    results = {}
    
    def enrich_single(resume_id: str) -> tuple[str, dict]:
        """–û–±–æ–≥–∞—â–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ä–µ–∑—é–º–µ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        try:
            data = enrich_one(resume_id, tz_target)
            return resume_id, data
        except Exception as e:
            print(f"‚ö†Ô∏è  API enrich failed for {resume_id}: {e}")
            return resume_id, {}
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(resume_ids)} —Ä–µ–∑—é–º–µ –≤ {max_workers} –ø–æ—Ç–æ–∫–æ–≤...")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        future_to_id = {executor.submit(enrich_single, rid): rid for rid in resume_ids}
        
        completed = 0
        for future in as_completed(future_to_id):
            resume_id, data = future.result()
            results[resume_id] = data
            completed += 1
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ä–µ–∑—é–º–µ
            if completed % 10 == 0 or completed == len(resume_ids):
                print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {completed}/{len(resume_ids)} —Ä–µ–∑—é–º–µ ({completed/len(resume_ids)*100:.1f}%)")
    
    print(f"üéâ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(results)} —Ä–µ–∑—é–º–µ")
    return results


def is_excluded_region(region_api: str, city_api: str, city_web: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–∫–ª—é—á–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –ø–æ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É.
    –ò—Å–∫–ª—é—á–∞–µ–º: –ß–µ—á–Ω—è, –î–∞–≥–µ—Å—Ç–∞–Ω, –ò–Ω–≥—É—à–µ—Ç–∏—è, –¢—É–≤–∞
    """
    excluded_regions = {
        "—á–µ—á–µ–Ω—Å–∫–∞—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞", "—á–µ—á–Ω—è", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ —á–µ—á–Ω—è",
        "–¥–∞–≥–µ—Å—Ç–∞–Ω", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ –¥–∞–≥–µ—Å—Ç–∞–Ω", 
        "–∏–Ω–≥—É—à–µ—Ç–∏—è", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ –∏–Ω–≥—É—à–µ—Ç–∏—è",
        "—Ç—É–≤–∞", "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ —Ç—ã–≤–∞", "—Ç—ã–≤–∞"
    }
    
    excluded_cities = {
        "–≥—Ä–æ–∑–Ω—ã–π", "–º–∞—Ö–∞—á–∫–∞–ª–∞", "–Ω–∞–∑—Ä–∞–Ω—å", "–∫—ã–∑—ã–ª", "–º–∞–≥–∞—Å"
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–≥–∏–æ–Ω –∏–∑ API
    if region_api:
        region_lower = region_api.lower().strip()
        if any(excluded in region_lower for excluded in excluded_regions):
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ä–æ–¥ –∏–∑ API
    if city_api:
        city_lower = city_api.lower().strip()
        if city_lower in excluded_cities:
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ä–æ–¥ –∏–∑ web-–¥–∞–Ω–Ω—ã—Ö (fallback)
    if city_web:
        city_lower = city_web.lower().strip()
        if city_lower in excluded_cities:
            return True
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –≤ —Å—Ç—Ä–æ–∫–µ –≥–æ—Ä–æ–¥–∞ (—á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç "–≥. –ì—Ä–æ–∑–Ω—ã–π, –ß–µ—á–µ–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞")
        if any(excluded in city_lower for excluded in excluded_regions):
            return True
    
    return False


def create_today_sheet(df: pd.DataFrame, stop_df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç '–Ω–∞_—Å–µ–≥–æ–¥–Ω—è' —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π:
    1. updated_at_web –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    2. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É (–ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É)
    3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º (–ß–µ—á–Ω—è, –î–∞–≥–µ—Å—Ç–∞–Ω, –ò–Ω–≥—É—à–µ—Ç–∏—è, –¢—É–≤–∞)
    """
    if df.empty:
        return pd.DataFrame()
    
    # 1. –§–∏–ª—å—Ç—Ä –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞)
    cutoff_time = datetime.now() - timedelta(hours=24)
    
    today_df = df.copy()
    if "updated_at_web" in today_df.columns:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        today_df["updated_at_web"] = pd.to_datetime(today_df["updated_at_web"], errors="coerce")
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        mask_recent = today_df["updated_at_web"] >= cutoff_time
        today_df = today_df[mask_recent]
    
    if today_df.empty:
        return pd.DataFrame()
    
    # 2. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É (—Ç–µ–ª–µ—Ñ–æ–Ω—ã)
    if not stop_df.empty and "phone_api" in today_df.columns:
        today_df["_phone_clean"] = _clean_phone_series(today_df["phone_api"]).fillna("")
        stop_phones = set(_clean_phone_series(stop_df[_DEF_COLS["phone"]]).fillna(""))
        stop_phones.discard("")  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
        
        if stop_phones:
            mask_not_in_stoplist = ~today_df["_phone_clean"].isin(stop_phones)
            today_df = today_df[mask_not_in_stoplist]
        
        today_df = today_df.drop(columns=["_phone_clean"], errors="ignore")
    
    if today_df.empty:
        return pd.DataFrame()
    
    # 3. –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ city_web, —Ç–∞–∫ –∫–∞–∫ API –ø–æ–ª—è —É–¥–∞–ª–µ–Ω—ã)
    mask_not_excluded_region = ~today_df.apply(
        lambda row: is_excluded_region(
            "",  # region_api —É–¥–∞–ª–µ–Ω–æ
            "",  # city_api —É–¥–∞–ª–µ–Ω–æ
            row.get("city_web", "")
        ), 
        axis=1
    )
    today_df = today_df[mask_not_excluded_region]
    
    return today_df.reset_index(drop=True)


def process_resumes_parallel(uniq: list, tz_target, num_threads: int) -> dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—é–º–µ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º API enrichment."""
    # ENRICH —á–µ—Ä–µ–∑ Avito API ‚Üí tz_target (–ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û)
    resume_ids = [rec.get("resume_id") for rec in uniq if rec.get("resume_id")]
    resume_ids = [rid for rid in resume_ids if rid]  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
    
    if resume_ids:
        api_cache = enrich_resume_batch(resume_ids, tz_target, max_workers=num_threads)
    else:
        api_cache = {}
    
    return api_cache


# ========== MAIN ==========
def main():
    from openpyxl.utils import get_column_letter

    tz_name = _parse_tz_arg(sys.argv) or os.getenv("AVITO_TZ") or DEFAULT_TZ_NAME
    tz_target = _get_tz(tz_name)
    num_threads = _parse_threads_arg(sys.argv)

    limit = _parse_limit_arg(sys.argv)
    if limit is None:
        limit = ask_limit_from_user()

    print(f"üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏: –ª–∏–º–∏—Ç={limit or '–≤—Å–µ'}, –ø–æ—Ç–æ–∫–æ–≤={num_threads}, —á–∞—Å–æ–≤–æ–π_–ø–æ—è—Å={tz_name}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —á–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    global CHATS_DATA
    CHATS_DATA = load_chats_from_api()
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(CHATS_DATA)} —á–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

    USER_DATA_DIR.mkdir(parents=True, exist_ok=True)
    with sync_playwright() as p:
        context = p.chromium.launch_persistent_context(
            user_data_dir=str(USER_DATA_DIR),
            headless=False,
            viewport=None,
            args=["--disable-blink-features=AutomationControlled", "--no-sandbox"],
        )
        context.set_default_timeout(NAV_TIMEOUT)
        context.set_default_navigation_timeout(NAV_TIMEOUT)
        page = context.new_page()

        try:
            page.goto(HOME_URL, wait_until="domcontentloaded")
        except PwError:
            pass

        input(f"\n–û—Ç–∫—Ä—ã–ª—Å—è –±—Ä–∞—É–∑–µ—Ä. –í–æ–π–¥–∏—Ç–µ –≤ Avito –∏ –Ω–∞–∂–º–∏—Ç–µ Enter –∑–¥–µ—Å—å...\n(–¢–µ–∫—É—â–∏–π TZ: {tz_name})\n–°—Ç–æ–ø–ª–∏—Å—Ç –∏–∑: {STOPLIST_DIR}\n")

        goto_resilient(page, TARGET_URL, "**/profile/paid-cvs*")
        total_cards_est = robust_scroll(page, need_count=limit)

        records = page.evaluate(EXTRACT_JS) or []
        if limit is not None:
            records = records[:limit]

        # –¥–µ–¥—É–ø
        uniq, seen = [], set()
        for r in records:
            key = r.get('resume_id') or r.get('link') or r.get('candidate_name_web')
            if key and key not in seen:
                seen.add(key)
                uniq.append(r)
                if limit is not None and len(uniq) >= limit:
                    break

        # –æ—Ñ–ª–∞–π–Ω-—Å–Ω–∏–º–æ–∫ (MHTML –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É, —É–¥–∞–ª–∏–º –ø–æ–∑–∂–µ)
        ts = datetime.now(tz_target).strftime("%Y%m%d-%H%M%S")
        mhtml_path = OUTPUT_DIR / f"avito_paid_cvs_{ts}.mhtml"
        save_as_mhtml(page, mhtml_path)

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ API
        api_cache = process_resumes_parallel(uniq, tz_target, num_threads)

        # –∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É
        df = pd.DataFrame.from_records(uniq)

        # –ª–æ–∫–∞–ª—å–Ω—ã–π now –¥–ª—è web-–¥–∞—Ç
        now_local_naive = datetime.now(tz_target).replace(tzinfo=None)

        # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç –∏–∑ –≤–µ–±–∞ ‚Üí *_web (naive, –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è TZ)
        for col in ("purchased_at_web", "updated_at_web"):
            if col in df.columns:
                df[col] = df[col].apply(lambda s: parse_ru_dt(s, now=now_local_naive))

        # –¥–æ–±–∞–≤–∏–º API-–ø–æ–ª—è (–±–µ—Ä—ë–º –∏–∑ api_cache)
        def _get(rid, key):
            return (api_cache.get(str(rid)) or {}).get(key, "")

        api_columns = [
            "fio_api",            # –Ω—É–∂–µ–Ω –¥–ª—è excluded_df/–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏, –Ω–µ –≤—ã–≤–æ–¥–∏–º –≤ paid_cvs
            "phone_api", "email_api", "chat_id_api", "avito_id",
            "update_time_api",    # –Ω—É–∂–µ–Ω –¥–ª—è api_difference —Ä–∞—Å—á—ë—Ç–∞
            "updated_at_api",     # –¥–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ API –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å web
            "desired_title_api",
            # –£–¥–∞–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ API –ø–æ–ª—è: "location_api", "city_api", "region_api"
            "chat_status", "last_message_direction", "last_message_text",  # –Ω–æ–≤—ã–µ –ø–æ–ª—è v11
            "json_open", "json_paid",
        ]
        for c in api_columns:
            df[c] = df["resume_id"].map(lambda x: _get(x, c))

        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –°–¢–û–ü-–õ–ò–°–¢ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        stop_df, stoplist_file_stats = build_stoplist_from_output()
        stop_count = len(stop_df)
        excluded_df = pd.DataFrame(columns=[
            "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–ò—Å—Ç–æ—á–Ω–∏–∫", "respond_status"
        ])

        if stop_count > 0 and "phone_api" in df.columns:
            df["_phone_clean"] = _clean_phone_series(df["phone_api"]).fillna("")
            stop_df["_phone_clean"] = _clean_phone_series(stop_df[_DEF_COLS["phone"]]).fillna("")

            merged = df.merge(
                stop_df[["_phone_clean", _DEF_COLS["fio"], _DEF_COLS["comment"], "–§–∞–π–ª", "–õ–∏—Å—Ç"]],
                on="_phone_clean", how="left"
            )

            mask_ex = merged[_DEF_COLS["comment"]].notna() | merged[_DEF_COLS["fio"]].notna()

            if mask_ex.any():
                merged["respond_status"] = merged.apply(
                    lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
                    axis=1
                )
                excluded_df = merged.loc[mask_ex, [
                    "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
                    _DEF_COLS["comment"], _DEF_COLS["fio"], "–§–∞–π–ª", "–õ–∏—Å—Ç", "respond_status"
                ]].rename(columns={
                    _DEF_COLS["comment"]: "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞",
                    _DEF_COLS["fio"]: "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞",
                })

            df = merged.loc[~mask_ex, df.columns].copy()
            df = df.drop(columns=["_phone_clean"], errors="ignore")
        else:
            df = df.copy()

        # –õ–∏–Ω–∫ –∏–∑ API (fallback ‚Äî web)
        def _build_precise_link(row) -> str:
            try:
                js = json.loads(row.get("json_open") or "{}")
                url_val = js.get("url") or js.get("uri") or (js.get("links") or {}).get("self") or js.get("link") or ""
                if url_val:
                    u = str(url_val)
                    return u if u.startswith("http") else ("https://www.avito.ru" + u)
            except Exception:
                pass
            w = str(row.get("link") or "")
            if w:
                return w if w.startswith("http") else ("https://www.avito.ru" + w)
            return ""

        df["link"] = df.apply(_build_precise_link, axis=1)

        # –ù–û–í–û–ï: ¬´–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç¬ª –∏–∑ chat_id_api
        df["–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç"] = df["chat_id_api"].apply(
            lambda x: f"https://www.avito.ru/profile/messenger/channel/{str(x).strip()}"
            if isinstance(x, str) and str(x).strip() else (
                f"https://www.avito.ru/profile/messenger/channel/{x}" if (x is not None and str(x).strip()) else ""
            )
        )

        # api_difference: –¥–Ω–∏ (updated_at_web - update_time_api)
        def _days_diff(a, b):
            try:
                if pd.isna(a) or pd.isna(b):
                    return pd.NA
                return int((pd.Timestamp(a) - pd.Timestamp(b)).days)
            except Exception:
                return pd.NA

        df["api_difference"] = df.apply(lambda r: _days_diff(r.get("updated_at_web"), r.get("update_time_api")), axis=1)

        # respond_status
        df["respond_status"] = df.apply(
            lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
            axis=1
        )

        # –∑–∞–∫—Ä—ã—Ç—ã–µ (json_paid –ø—É—Å—Ç–æ) ‚Üí –æ—Ç–¥–µ–ª—å–Ω—ã–π –ª–∏—Å—Ç
        def _is_json_paid_empty(v) -> bool:
            if pd.isna(v):
                return True
            s = str(v).strip()
            if not s:
                return True
            try:
                js = json.loads(s)
                if js in ({}, [], None):
                    return True
            except Exception:
                if s.lower() in ("{}", "[]", "null"):
                    return True
            return False

        if "json_paid" in df.columns:
            closed_mask = df["json_paid"].apply(_is_json_paid_empty)
        else:
            closed_mask = pd.Series(False, index=df.index)

        closed_df = df.loc[closed_mask].copy()
        if not closed_df.empty:
            closed_df["respond_status"] = closed_df.apply(
                lambda r: "NO_ANSWER" if ((not r.get("avito_id")) and r.get("chat_id_api")) else "",
                axis=1
            )

        # –∏–∑ —Ä–∞–±–æ—á–∏—Ö df –∏—Å–∫–ª—é—á–∞–µ–º –∑–∞–∫—Ä—ã—Ç—ã–µ
        df = df.loc[~closed_mask].copy()

        # NO_ANSWER –ª–∏—Å—Ç (–Ω–µ —É–¥–∞–ª—è–µ–º –∏–∑ df)
        no_answer_mask = df.apply(lambda r: (not r.get("avito_id")) and bool(r.get("chat_id_api")), axis=1)
        no_answer_df = df.loc[no_answer_mask].copy()
        if not no_answer_df.empty:
            no_answer_df["respond_status"] = "NO_ANSWER"

        # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ (–Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ, max —Ä–∞–∑–Ω–∏—Ü–∞ ‚Üí min)
        def _sort_df_for_output(dframe: pd.DataFrame) -> pd.DataFrame:
            sort_by = []
            if "updated_at_web" in dframe.columns:
                sort_by.append("updated_at_web")
            if "api_difference" in dframe.columns:
                sort_by.append("api_difference")
            if sort_by:
                ascending_flags = [False] * len(sort_by)
                try:
                    return dframe.sort_values(by=sort_by, ascending=ascending_flags, na_position="last")
                except Exception:
                    return dframe
            return dframe

        # –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–∏—Å—Ç–∞ "–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤" —Å —É—á–µ—Ç–æ–º —Å—Ç–∞—Ç—É—Å–æ–≤ —á–∞—Ç–æ–≤
        def _sort_df_for_calls(dframe: pd.DataFrame) -> pd.DataFrame:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            def get_priority(row):
                job_status = str(row.get("job_search_status_web", "")).lower()
                ready_start = str(row.get("ready_to_start_web", "")).lower()
                chat_status = str(row.get("chat_status", ""))
                
                # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫–∞–Ω–¥–∏–¥–∞—Ç –Ω–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω
                if chat_status == ChatStatus.NOT_INTERESTED.value:
                    return 9
                
                # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –≥–æ—Ç–æ–≤ –∑–∞–≤—Ç—Ä–∞/—Å—Ä–∞–∑—É + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if job_status and ready_start and chat_status == ChatStatus.READ_REPLIED.value:
                    return 1
                
                # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –≥–æ—Ç–æ–≤ –∑–∞–≤—Ç—Ä–∞/—Å—Ä–∞–∑—É
                if job_status and ready_start:
                    return 2
                
                # –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if job_status and chat_status == ChatStatus.READ_REPLIED.value:
                    return 3
                
                # –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω–æ –∏—â–µ—Ç —Ä–∞–±–æ—Ç—É
                if job_status:
                    return 4
                
                # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –≥–æ—Ç–æ–≤ –Ω–∞—á–∞—Ç—å –±—ã—Å—Ç—Ä–æ + –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ
                if ready_start and chat_status == ChatStatus.READ_REPLIED.value:
                    return 5
                
                # –ù–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: —Ç–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤ –Ω–∞—á–∞—Ç—å –±—ã—Å—Ç—Ä–æ
                if ready_start:
                    return 6
                
                # –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —á–∞—Ç–µ, –Ω–æ –±–µ–∑ –¥—Ä—É–≥–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
                if chat_status == ChatStatus.READ_REPLIED.value:
                    return 7
                
                # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π: —á–∏—Ç–∞–µ—Ç, –Ω–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç
                if chat_status == ChatStatus.READ_NO_REPLY.value:
                    return 8
                
                # –û–±—ã—á–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤
                return 10
            
            dframe = dframe.copy()
            dframe["_priority"] = dframe.apply(get_priority, axis=1)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (1-10) ‚Üí –Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ ‚Üí –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞
            sort_by = ["_priority"]
            ascending_flags = [True]  # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é (1 = –≤—ã—Å—à–∏–π)
            
            if "updated_at_web" in dframe.columns:
                sort_by.append("updated_at_web")
                ascending_flags.append(False)
            if "api_difference" in dframe.columns:
                sort_by.append("api_difference")
                ascending_flags.append(False)
            
            try:
                result = dframe.sort_values(by=sort_by, ascending=ascending_flags, na_position="last")
                # –£–¥–∞–ª—è–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
                result = result.drop(columns=["_priority"])
                return result
            except Exception:
                return dframe

        # –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (purchased_at_web ‚Äî –ü–ï–†–í–ê–Ø)
        desired_order = [
            "purchased_at_web",
            "updated_at_web", "updated_at_api", "candidate_name_web", "job_search_status_web", "ready_to_start_web",
            "chat_status", "last_message_direction", "last_message_text",
            "phone_api", "email_api", "desired_title_api", "city_web",
            # –£–¥–∞–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ API –ø–æ–ª—è: "city_api", "region_api", "location_api", "avito_id"
            "respond_status", "json_open", "json_paid", "link", "–°—Å—ã–ª–∫–∞ –Ω–∞ —á–∞—Ç", "chat_id_api", 
            "resume_id", "api_difference"
        ]

        # –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –ø–æ –º–∞–∫—Å. –¥–ª–∏–Ω–µ (header + –∑–Ω–∞—á–µ–Ω–∏—è)
        def _set_column_widths_autofit(ws, df_sheet):
            for i, col in enumerate(df_sheet.columns, start=1):
                col_letter = get_column_letter(i)
                header = str(col)
                values = df_sheet[col].astype(str).replace("nan", "").fillna("").tolist()
                max_len = len(header)
                for v in values:
                    l = len(v)
                    if l > max_len:
                        max_len = l
                width = max_len + 2
                if width < 4:
                    width = 4
                ws.column_dimensions[col_letter].width = width

        # ===== –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ Excel –≤ –ù–û–í–û–ï –º–µ—Å—Ç–æ –∏ —É–¥–∞–ª–µ–Ω–∏–µ MHTML =====
        OUTPUT_SAVE_DIR = Path(r"C:\ManekiNeko\AVITO_API\output").resolve()
        OUTPUT_SAVE_DIR.mkdir(parents=True, exist_ok=True)

        now_dt = datetime.now(tz_target)
        date_part = now_dt.strftime("%d%m%Y")     # –î–î–ú–ú–ì–ì–ì–ì
        time_part = now_dt.strftime("%M_%S")      # –ú–ú_–°–°
        excel_name = f"{date_part}_–í—ã–≥—Ä—É–∑–∫–∞_–ê–ú–û_{time_part}.xlsx"
        excel_path = OUTPUT_SAVE_DIR / excel_name

        with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
            # PAID_CVS
            df_out = _sort_df_for_output(df)
            cols_full = [c for c in desired_order if c in df_out.columns]
            df_out[cols_full].to_excel(writer, index=False, sheet_name="paid_cvs")
            ws = writer.sheets["paid_cvs"]
            _set_column_widths_autofit(ws, df_out[cols_full])

            # NO_ANSWER
            if not no_answer_df.empty:
                noans_out = _sort_df_for_output(no_answer_df)
                cols_noans = [c for c in desired_order if c in noans_out.columns]
                noans_out[cols_noans].to_excel(writer, index=False, sheet_name="NO_ANSWER")
                ws_no = writer.sheets["NO_ANSWER"]
                _set_column_widths_autofit(ws_no, noans_out[cols_noans])

            # —Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ
            if not closed_df.empty:
                closed_out = _sort_df_for_output(closed_df)
                cols_closed = [c for c in desired_order if c in closed_out.columns]
                closed_out[cols_closed].to_excel(writer, index=False, sheet_name="—Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ")
                ws_closed = writer.sheets["—Ä–µ–∑—é–º–µ –∑–∞–∫—Ä—ã—Ç–æ"]
                _set_column_widths_autofit(ws_closed, closed_out[cols_closed])

            # –î–ª—è_–∑–≤–æ–Ω–∫–æ–≤ (–±–µ–∑ json_open/json_paid) —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            df_calls = df.copy()
            df_calls = _sort_df_for_calls(df_calls)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—É—é —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É
            cols_calls = [c for c in desired_order if c in df_calls.columns and c not in ("json_open", "json_paid")]
            df_calls[cols_calls].to_excel(writer, index=False, sheet_name="–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤")
            ws_calls = writer.sheets["–î–ª—è_–∑–≤–æ–Ω–∫–æ–≤"]
            _set_column_widths_autofit(ws_calls, df_calls[cols_calls])

            # –Ω–∞_—Å–µ–≥–æ–¥–Ω—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞, –±–µ–∑ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞, –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)
            today_df = create_today_sheet(df, stop_df)
            if not today_df.empty:
                today_df = _sort_df_for_output(today_df)
                cols_today = [c for c in desired_order if c in today_df.columns and c not in ("json_open", "json_paid")]
                today_df[cols_today].to_excel(writer, index=False, sheet_name="–Ω–∞_—Å–µ–≥–æ–¥–Ω—è")
                ws_today = writer.sheets["–Ω–∞_—Å–µ–≥–æ–¥–Ω—è"]
                _set_column_widths_autofit(ws_today, today_df[cols_today])
                print(f"üìÖ –õ–∏—Å—Ç '–Ω–∞_—Å–µ–≥–æ–¥–Ω—è': {len(today_df)} –∑–∞–ø–∏—Å–µ–π (24 —á–∞—Å–∞, –±–µ–∑ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞, –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤)")

            # –ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É
            if not excluded_df.empty:
                ex_cols_order = [c for c in [
                    "purchased_at_web", "resume_id", "link", "fio_api", "phone_api", "city_web",
                    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–ò–û_—Å—Ç–æ–ø–ª–∏—Å—Ç–∞", "–§–∞–π–ª", "–õ–∏—Å—Ç", "respond_status"
                ] if c in excluded_df.columns]
                excluded_df[ex_cols_order].to_excel(writer, index=False, sheet_name="–ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É")
                ws_ex = writer.sheets["–ò—Å–∫–ª—é—á–µ–Ω–æ_–ø–æ_—Å—Ç–æ–ø–ª–∏—Å—Ç—É"]
                _set_column_widths_autofit(ws_ex, excluded_df[ex_cols_order])

            # summary (–æ—Å—Ç–∞–≤–ª—è—é –∫–∞–∫ –µ—Å—Ç—å ‚Äî snapshot —Ö—Ä–∞–Ω–∏—Ç –∏–º—è —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ MHTML)
            pd.DataFrame({
                "metric": [
                    "count_unique", "count_scroll_estimate", "snapshot", "page", "tz_name",
                    "stoplist_dir", "stoplist_size", "excluded_by_stoplist",
                ],
                "value": [
                    len(df), total_cards_est, str(mhtml_path.name), TARGET_URL, tz_name,
                    str(STOPLIST_DIR), int(stop_count), int(len(excluded_df)),
                ],
            }).to_excel(writer, index=False, sheet_name="summary")

        # –£–¥–∞–ª—è–µ–º MHTML –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–ø–∏—Å–∏ Excel
        try:
            mhtml_path.unlink()
            print(f"MHTML —É–¥–∞–ª—ë–Ω: {mhtml_path}")
        except FileNotFoundError:
            pass
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å MHTML ({mhtml_path}): {e}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–æ–ø–ª–∏—Å—Ç—É
        if stoplist_file_stats:
            print(f"\nüìã –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç–æ–ø–ª–∏—Å—Ç–∞:")
            print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stop_count} –∑–∞–ø–∏—Å–µ–π")
            print(f"   –ò—Å–∫–ª—é—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(excluded_df)}")
            print(f"   –§–∞–π–ª—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏:")
            for filename, count in stoplist_file_stats.items():
                print(f"     ‚Ä¢ {filename}: {count} –∑–∞–ø–∏—Å–µ–π")
        else:
            print(f"\nüìã –°—Ç–æ–ø–ª–∏—Å—Ç –ø—É—Å—Ç (—Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ {STOPLIST_DIR})")

        print(f"\nüìä Excel: {excel_path}")

        context.close()

if __name__ == "__main__":
    main()
